{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "import copy\n",
    "import math \n",
    "import gzip\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "global device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genome_data(data_file):\n",
    "    data=open(data_file).read()\n",
    "    chromosomes_data = data.split('>')[1:]\n",
    "    return (chromosomes_data)\n",
    "\n",
    "def Read_bed_file(chromosomes_data,peak_file,seq_length,Chr_dict):\n",
    "    peaks = open(peak_file).readlines()\n",
    "    if Chr_dict==None:\n",
    "        Chr_dict = {}\n",
    "        i=0\n",
    "        for chrom_data in chromosomes_data:\n",
    "            ref = chrom_data.split('\\n')[0].split(' ')[-1][1:-1]\n",
    "            Chr_dict[ref]=i\n",
    "            i+=1\n",
    "        Chr_dict['chromosome=Mito'] = Chr_dict.pop('top=circular')\n",
    "    peak_sequences = []\n",
    "    for peak in peaks:\n",
    "        peak_split = peak.split('\\t')\n",
    "        Chr = 'chromosome='+str(peak_split[0])\n",
    "        if Chr in Chr_dict:\n",
    "            chrom_seq = ''.join(chromosomes_data[Chr_dict[Chr]].split('\\n')[1:])\n",
    "            start_idx = max(int(peak_split[1])-seq_length//2,0)\n",
    "            end_idx = min(int(len(chrom_seq)), start_idx+seq_length)\n",
    "            if end_idx == len(chrom_seq):\n",
    "                start_idx = end_idx - seq_length\n",
    "            peak_sequences.append(chrom_seq[start_idx:end_idx])\n",
    "    return (peak_sequences)\n",
    "\n",
    "def Read_narrow_file(chromosomes_data,peak_file):\n",
    "    peaks = open(peak_file).readlines()\n",
    "    if Chr_dict==None:\n",
    "        Chr_dict = {}\n",
    "        i=0\n",
    "        for chrom_data in chromosomes_data:\n",
    "            ref = chrom_data.split('\\n')[0].split(' ')[-1][1:-1]\n",
    "            Chr_dict[ref]=i\n",
    "            i+=1\n",
    "        Chr_dict['chromosome=Mito'] = Chr_dict.pop('top=circular')\n",
    "    for peak in peaks:\n",
    "        peak_split = peak.split('\\t')\n",
    "        Chr = 'chromosome='+str(peak_split[0])\n",
    "        chrom_seq = ''.join(chromosomes_data[Chr_dict[Chr]].split('\\n')[1:])\n",
    "        if Chr in Chr_dict:\n",
    "            start_idx = max(int(peak_split[1])-seq_length//2,0)\n",
    "            end_idx = min(len(chrom_seq),start_idx+seq_length)\n",
    "            #end_idx = start_idx+seq_length\n",
    "            peak_sequences.append(chrom_seq[start_idx:end_idx])\n",
    "    return (peak_sequences)\n",
    "    return None\n",
    "\n",
    "def dinucshuffle(sequence):\n",
    "    b=[sequence[i:i+2] for i in range(0, len(sequence), 2)]\n",
    "    random.shuffle(b)\n",
    "    d=''.join([str(x) for x in b])\n",
    "    return d\n",
    "\n",
    "def seqtopad(sequence, motif_len):\n",
    "    rows=len(sequence)+2*motif_len-2\n",
    "    S=np.empty([rows,4])\n",
    "    base=['A', 'C', 'G', 'T']\n",
    "    for i in range(rows):\n",
    "        for j in range(4):\n",
    "            if (i-motif_len+1<len(sequence) and sequence[i-motif_len+1]=='N' \n",
    "                or i<motif_len-1 or i>len(sequence)+motif_len-2):\n",
    "                S[i,j]=np.float32(0.25)\n",
    "            elif sequence[i-motif_len+1]==base[j]:\n",
    "                S[i,j]=np.float32(1)\n",
    "            else:\n",
    "                S[i,j]=np.float32(0)\n",
    "    return np.transpose(S)\n",
    "\n",
    "def extract_data(data_file,peak_file,motif_length=24,seq_length=150,Chr_dict=None):\n",
    "    chromosomes_data = genome_data(data_file)\n",
    "    if '.bed' in peak_file:\n",
    "        peak_sequences = Read_bed_file(chromosomes_data,peak_file,seq_length,Chr_dict)\n",
    "    else :\n",
    "        peak_sequences = Read_narrow_file(chromosomes_data,peak_file,seq_length,Chr_dict)\n",
    "    alldata = []\n",
    "    for seq in peak_sequences:\n",
    "        alldata.append([seqtopad(seq,motif_length),[1]])#\n",
    "        alldata.append([seqtopad(dinucshuffle(seq),motif_length),[0]])#\n",
    "    random.shuffle(alldata)\n",
    "    size=int(len(alldata)/5)\n",
    "    train_data=alldata[:4*size]\n",
    "    valid_data=alldata[4*size:int(4.5*size)]\n",
    "    test_data = alldata[int(4.5*size):]\n",
    "    return train_data,valid_data,test_data,alldata,peak_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_model(model,train_loader,valid_loader, l_rate=0.01 ,  maxepochs=100,epochs_for_early_stop=0,verbose=False):\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "    counter = 0\n",
    "    nepochs=0\n",
    "    valid_losses =[]\n",
    "    train_losses = []\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=l_rate,momentum=0.9,nesterov=True,weight_decay=1e-02)\n",
    "    criterion = nn.BCELoss(reduction='mean')\n",
    "    while nepochs<maxepochs:\n",
    "        model.train()\n",
    "        train_loss=0\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)#\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "        if verbose:\n",
    "            print('Model trained for {0} epochs out of {2}. Training loss is {1}'.format(nepochs+1,loss.item(),maxepochs))\n",
    "        train_losses.append(train_loss/(i+1))\n",
    "        with torch.no_grad():\n",
    "            model.eval() \n",
    "            valid_loss=0\n",
    "            for i, (data, target) in enumerate(valid_loader):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = F.binary_cross_entropy(output, target)#\n",
    "                valid_loss+=loss.item()\n",
    "            valid_losses.append(valid_loss/(i+1))\n",
    "        counter+=1\n",
    "        nepochs +=1\n",
    "        if epochs_for_early_stop>0:\n",
    "            if valid_losses[-1]<best_loss:\n",
    "                if verbose:\n",
    "                    print('Validation loss decreased from {0} to {1}'.format(best_loss,valid_losses[-1]))\n",
    "                best_loss = valid_losses[-1]\n",
    "                best_model = model\n",
    "                counter = 0\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('Counter for early stopping: {0} out of {1}'.format(counter,epochs_for_early_stop))\n",
    "                if counter == epochs_for_early_stop:\n",
    "                    print('early stopping at epoch ', nepochs-counter)\n",
    "                    return (best_model,nepochs-counter,train_losses,valid_losses)\n",
    "    print('no early stopping')\n",
    "    return (best_model,nepochs,train_losses,valid_losses)\n",
    "\n",
    "def Test_model(model,test_loader):\n",
    "    with torch.no_grad():\n",
    "        best_model.eval()\n",
    "        pred_list = []\n",
    "        labels_list = []\n",
    "        for i, (data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = best_model(data)\n",
    "            pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
    "            labels=target.cpu().numpy().reshape(output.shape[0])\n",
    "            pred_list.append(pred)\n",
    "            labels_list.append(labels)\n",
    "        labels = np.concatenate(labels_list)\n",
    "        predictions = np.concatenate(pred_list)\n",
    "        auc = metrics.roc_auc_score(labels, predictions)\n",
    "        print('AUC on test data ', auc)\n",
    "    return (auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, xy=None):\n",
    "        self.x_data=np.asarray([el[0] for el in xy],dtype=np.float32)\n",
    "        self.y_data =np.asarray([el[1] for el in xy ],dtype=np.float32)\n",
    "        self.x_data = torch.from_numpy(self.x_data)\n",
    "        self.y_data = torch.from_numpy(self.y_data)\n",
    "        self.length=len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, num_motif , motif_len):\n",
    "        super(Network, self).__init__()\n",
    "        self.num_motif = num_motif\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(4, num_motif, kernel_size=motif_len))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_motif , num_motif),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(num_motif, 1),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x,_ = torch.max(x, dim=2)\n",
    "        predict = self.classifier(x)\n",
    "        return predict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1584, 198, 202)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = 'Data/S288C_reference_sequence_R64-3-1_20210421.fsa'\n",
    "peak_file = 'Data/Condensin_peaks_Log.bed'\n",
    "seq_length = 150\n",
    "motif_length = 24\n",
    "train_data,valid_data,test_data,alldata,peak_sequences = extract_data(data_file,peak_file,motif_length,seq_length)\n",
    "len(train_data),len(valid_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=dataset(train_data)\n",
    "valid_dataset=dataset(valid_data)\n",
    "test_dataset=dataset(test_data)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for 1 epochs out of 500. Training loss is 0.6838752627372742\n",
      "Validation loss decreased from inf to 0.6957444399595261\n",
      "Model trained for 2 epochs out of 500. Training loss is 0.6901106238365173\n",
      "Validation loss decreased from 0.6957444399595261 to 0.6941875964403152\n",
      "Model trained for 3 epochs out of 500. Training loss is 0.6911100149154663\n",
      "Validation loss decreased from 0.6941875964403152 to 0.6939574182033539\n",
      "Model trained for 4 epochs out of 500. Training loss is 0.6908245086669922\n",
      "Validation loss decreased from 0.6939574182033539 to 0.6939534991979599\n",
      "Model trained for 5 epochs out of 500. Training loss is 0.6904346346855164\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 6 epochs out of 500. Training loss is 0.6901440620422363\n",
      "Validation loss decreased from 0.6939534991979599 to 0.693948358297348\n",
      "Model trained for 7 epochs out of 500. Training loss is 0.6899121999740601\n",
      "Validation loss decreased from 0.693948358297348 to 0.6939028650522232\n",
      "Model trained for 8 epochs out of 500. Training loss is 0.6897168159484863\n",
      "Validation loss decreased from 0.6939028650522232 to 0.6938548237085342\n",
      "Model trained for 9 epochs out of 500. Training loss is 0.6895901560783386\n",
      "Validation loss decreased from 0.6938548237085342 to 0.6938163191080093\n",
      "Model trained for 10 epochs out of 500. Training loss is 0.6894421577453613\n",
      "Validation loss decreased from 0.6938163191080093 to 0.6937784552574158\n",
      "Model trained for 11 epochs out of 500. Training loss is 0.6892785429954529\n",
      "Validation loss decreased from 0.6937784552574158 to 0.6937536597251892\n",
      "Model trained for 12 epochs out of 500. Training loss is 0.6891559958457947\n",
      "Validation loss decreased from 0.6937536597251892 to 0.6937138140201569\n",
      "Model trained for 13 epochs out of 500. Training loss is 0.6891154050827026\n",
      "Validation loss decreased from 0.6937138140201569 to 0.6936641335487366\n",
      "Model trained for 14 epochs out of 500. Training loss is 0.689034640789032\n",
      "Validation loss decreased from 0.6936641335487366 to 0.69363634288311\n",
      "Model trained for 15 epochs out of 500. Training loss is 0.6889466047286987\n",
      "Validation loss decreased from 0.69363634288311 to 0.6936134099960327\n",
      "Model trained for 16 epochs out of 500. Training loss is 0.6888601183891296\n",
      "Validation loss decreased from 0.6936134099960327 to 0.6935902833938599\n",
      "Model trained for 17 epochs out of 500. Training loss is 0.6887502074241638\n",
      "Validation loss decreased from 0.6935902833938599 to 0.693571463227272\n",
      "Model trained for 18 epochs out of 500. Training loss is 0.688663125038147\n",
      "Validation loss decreased from 0.693571463227272 to 0.6935514509677887\n",
      "Model trained for 19 epochs out of 500. Training loss is 0.6885714530944824\n",
      "Validation loss decreased from 0.6935514509677887 to 0.6935313493013382\n",
      "Model trained for 20 epochs out of 500. Training loss is 0.6884903907775879\n",
      "Validation loss decreased from 0.6935313493013382 to 0.6935086399316788\n",
      "Model trained for 21 epochs out of 500. Training loss is 0.6884005069732666\n",
      "Validation loss decreased from 0.6935086399316788 to 0.6934866160154343\n",
      "Model trained for 22 epochs out of 500. Training loss is 0.6883116960525513\n",
      "Validation loss decreased from 0.6934866160154343 to 0.693464070558548\n",
      "Model trained for 23 epochs out of 500. Training loss is 0.6882165670394897\n",
      "Validation loss decreased from 0.693464070558548 to 0.6934469193220139\n",
      "Model trained for 24 epochs out of 500. Training loss is 0.6881291270256042\n",
      "Validation loss decreased from 0.6934469193220139 to 0.6934312582015991\n",
      "Model trained for 25 epochs out of 500. Training loss is 0.6880217790603638\n",
      "Validation loss decreased from 0.6934312582015991 to 0.6934207677841187\n",
      "Model trained for 26 epochs out of 500. Training loss is 0.6879216432571411\n",
      "Validation loss decreased from 0.6934207677841187 to 0.6934109628200531\n",
      "Model trained for 27 epochs out of 500. Training loss is 0.6878182291984558\n",
      "Validation loss decreased from 0.6934109628200531 to 0.6934020668268204\n",
      "Model trained for 28 epochs out of 500. Training loss is 0.6877061724662781\n",
      "Validation loss decreased from 0.6934020668268204 to 0.6933954507112503\n",
      "Model trained for 29 epochs out of 500. Training loss is 0.6876077651977539\n",
      "Validation loss decreased from 0.6933954507112503 to 0.6933822482824326\n",
      "Model trained for 30 epochs out of 500. Training loss is 0.6874877214431763\n",
      "Validation loss decreased from 0.6933822482824326 to 0.6933718323707581\n",
      "Model trained for 31 epochs out of 500. Training loss is 0.6873905658721924\n",
      "Validation loss decreased from 0.6933718323707581 to 0.6933441609144211\n",
      "Model trained for 32 epochs out of 500. Training loss is 0.6872608661651611\n",
      "Validation loss decreased from 0.6933441609144211 to 0.6933095008134842\n",
      "Model trained for 33 epochs out of 500. Training loss is 0.6871177554130554\n",
      "Validation loss decreased from 0.6933095008134842 to 0.6932728290557861\n",
      "Model trained for 34 epochs out of 500. Training loss is 0.6870152950286865\n",
      "Validation loss decreased from 0.6932728290557861 to 0.693244457244873\n",
      "Model trained for 35 epochs out of 500. Training loss is 0.6868895292282104\n",
      "Validation loss decreased from 0.693244457244873 to 0.6932272464036942\n",
      "Model trained for 36 epochs out of 500. Training loss is 0.6867992281913757\n",
      "Validation loss decreased from 0.6932272464036942 to 0.6932001113891602\n",
      "Model trained for 37 epochs out of 500. Training loss is 0.6867336630821228\n",
      "Validation loss decreased from 0.6932001113891602 to 0.6931689977645874\n",
      "Model trained for 38 epochs out of 500. Training loss is 0.6866555213928223\n",
      "Validation loss decreased from 0.6931689977645874 to 0.6931366920471191\n",
      "Model trained for 39 epochs out of 500. Training loss is 0.6865800619125366\n",
      "Validation loss decreased from 0.6931366920471191 to 0.6930961012840271\n",
      "Model trained for 40 epochs out of 500. Training loss is 0.686496913433075\n",
      "Validation loss decreased from 0.6930961012840271 to 0.6930631101131439\n",
      "Model trained for 41 epochs out of 500. Training loss is 0.6863874197006226\n",
      "Validation loss decreased from 0.6930631101131439 to 0.6930408030748367\n",
      "Model trained for 42 epochs out of 500. Training loss is 0.6863023638725281\n",
      "Validation loss decreased from 0.6930408030748367 to 0.693014457821846\n",
      "Model trained for 43 epochs out of 500. Training loss is 0.6862150430679321\n",
      "Validation loss decreased from 0.693014457821846 to 0.6929922103881836\n",
      "Model trained for 44 epochs out of 500. Training loss is 0.6861123442649841\n",
      "Validation loss decreased from 0.6929922103881836 to 0.692969799041748\n",
      "Model trained for 45 epochs out of 500. Training loss is 0.6860458850860596\n",
      "Validation loss decreased from 0.692969799041748 to 0.6929415613412857\n",
      "Model trained for 46 epochs out of 500. Training loss is 0.6859659552574158\n",
      "Validation loss decreased from 0.6929415613412857 to 0.6929151564836502\n",
      "Model trained for 47 epochs out of 500. Training loss is 0.6859132647514343\n",
      "Validation loss decreased from 0.6929151564836502 to 0.6928909868001938\n",
      "Model trained for 48 epochs out of 500. Training loss is 0.6858450770378113\n",
      "Validation loss decreased from 0.6928909868001938 to 0.6928699612617493\n",
      "Model trained for 49 epochs out of 500. Training loss is 0.6857852935791016\n",
      "Validation loss decreased from 0.6928699612617493 to 0.6928481310606003\n",
      "Model trained for 50 epochs out of 500. Training loss is 0.6857139468193054\n",
      "Validation loss decreased from 0.6928481310606003 to 0.6928266137838364\n",
      "Model trained for 51 epochs out of 500. Training loss is 0.6856249570846558\n",
      "Validation loss decreased from 0.6928266137838364 to 0.6928118467330933\n",
      "Model trained for 52 epochs out of 500. Training loss is 0.6855450868606567\n",
      "Validation loss decreased from 0.6928118467330933 to 0.6927938908338547\n",
      "Model trained for 53 epochs out of 500. Training loss is 0.6854681968688965\n",
      "Validation loss decreased from 0.6927938908338547 to 0.6927739530801773\n",
      "Model trained for 54 epochs out of 500. Training loss is 0.6853874921798706\n",
      "Validation loss decreased from 0.6927739530801773 to 0.6927558332681656\n",
      "Model trained for 55 epochs out of 500. Training loss is 0.6852974891662598\n",
      "Validation loss decreased from 0.6927558332681656 to 0.6927381455898285\n",
      "Model trained for 56 epochs out of 500. Training loss is 0.6851832866668701\n",
      "Validation loss decreased from 0.6927381455898285 to 0.6927242130041122\n",
      "Model trained for 57 epochs out of 500. Training loss is 0.685081422328949\n",
      "Validation loss decreased from 0.6927242130041122 to 0.6927051544189453\n",
      "Model trained for 58 epochs out of 500. Training loss is 0.6849715113639832\n",
      "Validation loss decreased from 0.6927051544189453 to 0.6926870346069336\n",
      "Model trained for 59 epochs out of 500. Training loss is 0.684882402420044\n",
      "Validation loss decreased from 0.6926870346069336 to 0.6926646083593369\n",
      "Model trained for 60 epochs out of 500. Training loss is 0.6847996115684509\n",
      "Validation loss decreased from 0.6926646083593369 to 0.6926430016756058\n",
      "Model trained for 61 epochs out of 500. Training loss is 0.6847206950187683\n",
      "Validation loss decreased from 0.6926430016756058 to 0.6926220953464508\n",
      "Model trained for 62 epochs out of 500. Training loss is 0.6846610903739929\n",
      "Validation loss decreased from 0.6926220953464508 to 0.6925943940877914\n",
      "Model trained for 63 epochs out of 500. Training loss is 0.6845561265945435\n",
      "Validation loss decreased from 0.6925943940877914 to 0.6925739049911499\n",
      "Model trained for 64 epochs out of 500. Training loss is 0.6844873428344727\n",
      "Validation loss decreased from 0.6925739049911499 to 0.6925473362207413\n",
      "Model trained for 65 epochs out of 500. Training loss is 0.6844127178192139\n",
      "Validation loss decreased from 0.6925473362207413 to 0.6925242990255356\n",
      "Model trained for 66 epochs out of 500. Training loss is 0.6843112707138062\n",
      "Validation loss decreased from 0.6925242990255356 to 0.6925035715103149\n",
      "Model trained for 67 epochs out of 500. Training loss is 0.684222400188446\n",
      "Validation loss decreased from 0.6925035715103149 to 0.6924798488616943\n",
      "Model trained for 68 epochs out of 500. Training loss is 0.6841205358505249\n",
      "Validation loss decreased from 0.6924798488616943 to 0.6924598962068558\n",
      "Model trained for 69 epochs out of 500. Training loss is 0.6839990615844727\n",
      "Validation loss decreased from 0.6924598962068558 to 0.6924435347318649\n",
      "Model trained for 70 epochs out of 500. Training loss is 0.683867335319519\n",
      "Validation loss decreased from 0.6924435347318649 to 0.6924253851175308\n",
      "Model trained for 71 epochs out of 500. Training loss is 0.6837319135665894\n",
      "Validation loss decreased from 0.6924253851175308 to 0.6924044340848923\n",
      "Model trained for 72 epochs out of 500. Training loss is 0.683617115020752\n",
      "Validation loss decreased from 0.6924044340848923 to 0.6923834979534149\n",
      "Model trained for 73 epochs out of 500. Training loss is 0.6835152506828308\n",
      "Validation loss decreased from 0.6923834979534149 to 0.6923584938049316\n",
      "Model trained for 74 epochs out of 500. Training loss is 0.6834160089492798\n",
      "Validation loss decreased from 0.6923584938049316 to 0.6923350095748901\n",
      "Model trained for 75 epochs out of 500. Training loss is 0.6833347082138062\n",
      "Validation loss decreased from 0.6923350095748901 to 0.6923099905252457\n",
      "Model trained for 76 epochs out of 500. Training loss is 0.6832245588302612\n",
      "Validation loss decreased from 0.6923099905252457 to 0.6922919005155563\n",
      "Model trained for 77 epochs out of 500. Training loss is 0.6831316947937012\n",
      "Validation loss decreased from 0.6922919005155563 to 0.6922698318958282\n",
      "Model trained for 78 epochs out of 500. Training loss is 0.6830353736877441\n",
      "Validation loss decreased from 0.6922698318958282 to 0.6922460198402405\n",
      "Model trained for 79 epochs out of 500. Training loss is 0.6829587817192078\n",
      "Validation loss decreased from 0.6922460198402405 to 0.6922144144773483\n",
      "Model trained for 80 epochs out of 500. Training loss is 0.6828663349151611\n",
      "Validation loss decreased from 0.6922144144773483 to 0.6921847462654114\n",
      "Model trained for 81 epochs out of 500. Training loss is 0.6827780604362488\n",
      "Validation loss decreased from 0.6921847462654114 to 0.6921518743038177\n",
      "Model trained for 82 epochs out of 500. Training loss is 0.6826679706573486\n",
      "Validation loss decreased from 0.6921518743038177 to 0.6921249330043793\n",
      "Model trained for 83 epochs out of 500. Training loss is 0.6825467944145203\n",
      "Validation loss decreased from 0.6921249330043793 to 0.6920973211526871\n",
      "Model trained for 84 epochs out of 500. Training loss is 0.6824150085449219\n",
      "Validation loss decreased from 0.6920973211526871 to 0.6920710802078247\n",
      "Model trained for 85 epochs out of 500. Training loss is 0.682288646697998\n",
      "Validation loss decreased from 0.6920710802078247 to 0.6920416355133057\n",
      "Model trained for 86 epochs out of 500. Training loss is 0.6821867823600769\n",
      "Validation loss decreased from 0.6920416355133057 to 0.692009299993515\n",
      "Model trained for 87 epochs out of 500. Training loss is 0.6820640563964844\n",
      "Validation loss decreased from 0.692009299993515 to 0.6919821351766586\n",
      "Model trained for 88 epochs out of 500. Training loss is 0.6819307208061218\n",
      "Validation loss decreased from 0.6919821351766586 to 0.6919526159763336\n",
      "Model trained for 89 epochs out of 500. Training loss is 0.6818158030509949\n",
      "Validation loss decreased from 0.6919526159763336 to 0.6919202506542206\n",
      "Model trained for 90 epochs out of 500. Training loss is 0.6816921234130859\n",
      "Validation loss decreased from 0.6919202506542206 to 0.6918879300355911\n",
      "Model trained for 91 epochs out of 500. Training loss is 0.6815659403800964\n",
      "Validation loss decreased from 0.6918879300355911 to 0.6918541491031647\n",
      "Model trained for 92 epochs out of 500. Training loss is 0.6814329028129578\n",
      "Validation loss decreased from 0.6918541491031647 to 0.6918234527111053\n",
      "Model trained for 93 epochs out of 500. Training loss is 0.6812755465507507\n",
      "Validation loss decreased from 0.6918234527111053 to 0.6918010711669922\n",
      "Model trained for 94 epochs out of 500. Training loss is 0.681137204170227\n",
      "Validation loss decreased from 0.6918010711669922 to 0.6917712539434433\n",
      "Model trained for 95 epochs out of 500. Training loss is 0.6810304522514343\n",
      "Validation loss decreased from 0.6917712539434433 to 0.691736027598381\n",
      "Model trained for 96 epochs out of 500. Training loss is 0.6808966398239136\n",
      "Validation loss decreased from 0.691736027598381 to 0.6917048245668411\n",
      "Model trained for 97 epochs out of 500. Training loss is 0.6807723045349121\n",
      "Validation loss decreased from 0.6917048245668411 to 0.6916672885417938\n",
      "Model trained for 98 epochs out of 500. Training loss is 0.6806608438491821\n",
      "Validation loss decreased from 0.6916672885417938 to 0.691629484295845\n",
      "Model trained for 99 epochs out of 500. Training loss is 0.6805383563041687\n",
      "Validation loss decreased from 0.691629484295845 to 0.6915895640850067\n",
      "Model trained for 100 epochs out of 500. Training loss is 0.6804081797599792\n",
      "Validation loss decreased from 0.6915895640850067 to 0.6915491074323654\n",
      "Model trained for 101 epochs out of 500. Training loss is 0.6802793741226196\n",
      "Validation loss decreased from 0.6915491074323654 to 0.6915083527565002\n",
      "Model trained for 102 epochs out of 500. Training loss is 0.6801359057426453\n",
      "Validation loss decreased from 0.6915083527565002 to 0.6914707124233246\n",
      "Model trained for 103 epochs out of 500. Training loss is 0.6799743175506592\n",
      "Validation loss decreased from 0.6914707124233246 to 0.6914364099502563\n",
      "Model trained for 104 epochs out of 500. Training loss is 0.6798152923583984\n",
      "Validation loss decreased from 0.6914364099502563 to 0.6913996636867523\n",
      "Model trained for 105 epochs out of 500. Training loss is 0.6796585917472839\n",
      "Validation loss decreased from 0.6913996636867523 to 0.6913610696792603\n",
      "Model trained for 106 epochs out of 500. Training loss is 0.6794782876968384\n",
      "Validation loss decreased from 0.6913610696792603 to 0.6913266032934189\n",
      "Model trained for 107 epochs out of 500. Training loss is 0.6793266534805298\n",
      "Validation loss decreased from 0.6913266032934189 to 0.6912850439548492\n",
      "Model trained for 108 epochs out of 500. Training loss is 0.6791667938232422\n",
      "Validation loss decreased from 0.6912850439548492 to 0.6912410706281662\n",
      "Model trained for 109 epochs out of 500. Training loss is 0.6790027618408203\n",
      "Validation loss decreased from 0.6912410706281662 to 0.691199854016304\n",
      "Model trained for 110 epochs out of 500. Training loss is 0.6788272261619568\n",
      "Validation loss decreased from 0.691199854016304 to 0.6911571174860001\n",
      "Model trained for 111 epochs out of 500. Training loss is 0.6786447763442993\n",
      "Validation loss decreased from 0.6911571174860001 to 0.6911135166883469\n",
      "Model trained for 112 epochs out of 500. Training loss is 0.6784757375717163\n",
      "Validation loss decreased from 0.6911135166883469 to 0.691067561507225\n",
      "Model trained for 113 epochs out of 500. Training loss is 0.6782898902893066\n",
      "Validation loss decreased from 0.691067561507225 to 0.6910234540700912\n",
      "Model trained for 114 epochs out of 500. Training loss is 0.6780945658683777\n",
      "Validation loss decreased from 0.6910234540700912 to 0.6909793019294739\n",
      "Model trained for 115 epochs out of 500. Training loss is 0.6778938174247742\n",
      "Validation loss decreased from 0.6909793019294739 to 0.690937265753746\n",
      "Model trained for 116 epochs out of 500. Training loss is 0.6776862144470215\n",
      "Validation loss decreased from 0.690937265753746 to 0.6908933073282242\n",
      "Model trained for 117 epochs out of 500. Training loss is 0.6774864196777344\n",
      "Validation loss decreased from 0.6908933073282242 to 0.6908450424671173\n",
      "Model trained for 118 epochs out of 500. Training loss is 0.6773180961608887\n",
      "Validation loss decreased from 0.6908450424671173 to 0.6907892376184464\n",
      "Model trained for 119 epochs out of 500. Training loss is 0.6771170496940613\n",
      "Validation loss decreased from 0.6907892376184464 to 0.6907396763563156\n",
      "Model trained for 120 epochs out of 500. Training loss is 0.6769012212753296\n",
      "Validation loss decreased from 0.6907396763563156 to 0.6906883865594864\n",
      "Model trained for 121 epochs out of 500. Training loss is 0.6766934394836426\n",
      "Validation loss decreased from 0.6906883865594864 to 0.6906338334083557\n",
      "Model trained for 122 epochs out of 500. Training loss is 0.6764802932739258\n",
      "Validation loss decreased from 0.6906338334083557 to 0.6905784904956818\n",
      "Model trained for 123 epochs out of 500. Training loss is 0.6762850284576416\n",
      "Validation loss decreased from 0.6905784904956818 to 0.690520167350769\n",
      "Model trained for 124 epochs out of 500. Training loss is 0.6760568618774414\n",
      "Validation loss decreased from 0.690520167350769 to 0.6904665976762772\n",
      "Model trained for 125 epochs out of 500. Training loss is 0.6758213043212891\n",
      "Validation loss decreased from 0.6904665976762772 to 0.6904091984033585\n",
      "Model trained for 126 epochs out of 500. Training loss is 0.6756062507629395\n",
      "Validation loss decreased from 0.6904091984033585 to 0.6903485506772995\n",
      "Model trained for 127 epochs out of 500. Training loss is 0.6753665208816528\n",
      "Validation loss decreased from 0.6903485506772995 to 0.6902908533811569\n",
      "Model trained for 128 epochs out of 500. Training loss is 0.6751316785812378\n",
      "Validation loss decreased from 0.6902908533811569 to 0.6902297288179398\n",
      "Model trained for 129 epochs out of 500. Training loss is 0.674883246421814\n",
      "Validation loss decreased from 0.6902297288179398 to 0.6901684701442719\n",
      "Model trained for 130 epochs out of 500. Training loss is 0.6746151447296143\n",
      "Validation loss decreased from 0.6901684701442719 to 0.6901084333658218\n",
      "Model trained for 131 epochs out of 500. Training loss is 0.6743624210357666\n",
      "Validation loss decreased from 0.6901084333658218 to 0.6900413930416107\n",
      "Model trained for 132 epochs out of 500. Training loss is 0.6740970611572266\n",
      "Validation loss decreased from 0.6900413930416107 to 0.6899773627519608\n",
      "Model trained for 133 epochs out of 500. Training loss is 0.6738128662109375\n",
      "Validation loss decreased from 0.6899773627519608 to 0.689913347363472\n",
      "Model trained for 134 epochs out of 500. Training loss is 0.6735422015190125\n",
      "Validation loss decreased from 0.689913347363472 to 0.6898408085107803\n",
      "Model trained for 135 epochs out of 500. Training loss is 0.6732443571090698\n",
      "Validation loss decreased from 0.6898408085107803 to 0.6897753179073334\n",
      "Model trained for 136 epochs out of 500. Training loss is 0.6729253530502319\n",
      "Validation loss decreased from 0.6897753179073334 to 0.6897038966417313\n",
      "Model trained for 137 epochs out of 500. Training loss is 0.6726213693618774\n",
      "Validation loss decreased from 0.6897038966417313 to 0.689627930521965\n",
      "Model trained for 138 epochs out of 500. Training loss is 0.6723119616508484\n",
      "Validation loss decreased from 0.689627930521965 to 0.6895488500595093\n",
      "Model trained for 139 epochs out of 500. Training loss is 0.6720005869865417\n",
      "Validation loss decreased from 0.6895488500595093 to 0.6894704401493073\n",
      "Model trained for 140 epochs out of 500. Training loss is 0.6716825366020203\n",
      "Validation loss decreased from 0.6894704401493073 to 0.6893885433673859\n",
      "Model trained for 141 epochs out of 500. Training loss is 0.6713470816612244\n",
      "Validation loss decreased from 0.6893885433673859 to 0.6893037557601929\n",
      "Model trained for 142 epochs out of 500. Training loss is 0.6710151433944702\n",
      "Validation loss decreased from 0.6893037557601929 to 0.6892156451940536\n",
      "Model trained for 143 epochs out of 500. Training loss is 0.6706722974777222\n",
      "Validation loss decreased from 0.6892156451940536 to 0.6891263425350189\n",
      "Model trained for 144 epochs out of 500. Training loss is 0.6703366041183472\n",
      "Validation loss decreased from 0.6891263425350189 to 0.6890358626842499\n",
      "Model trained for 145 epochs out of 500. Training loss is 0.6699614524841309\n",
      "Validation loss decreased from 0.6890358626842499 to 0.6889480501413345\n",
      "Model trained for 146 epochs out of 500. Training loss is 0.6695868968963623\n",
      "Validation loss decreased from 0.6889480501413345 to 0.6888576745986938\n",
      "Model trained for 147 epochs out of 500. Training loss is 0.669224739074707\n",
      "Validation loss decreased from 0.6888576745986938 to 0.6887613236904144\n",
      "Model trained for 148 epochs out of 500. Training loss is 0.6688306331634521\n",
      "Validation loss decreased from 0.6887613236904144 to 0.6886661052703857\n",
      "Model trained for 149 epochs out of 500. Training loss is 0.6684293150901794\n",
      "Validation loss decreased from 0.6886661052703857 to 0.688564196228981\n",
      "Model trained for 150 epochs out of 500. Training loss is 0.6680401563644409\n",
      "Validation loss decreased from 0.688564196228981 to 0.6884546130895615\n",
      "Model trained for 151 epochs out of 500. Training loss is 0.6676353812217712\n",
      "Validation loss decreased from 0.6884546130895615 to 0.6883446872234344\n",
      "Model trained for 152 epochs out of 500. Training loss is 0.6671974062919617\n",
      "Validation loss decreased from 0.6883446872234344 to 0.6882316172122955\n",
      "Model trained for 153 epochs out of 500. Training loss is 0.6667684316635132\n",
      "Validation loss decreased from 0.6882316172122955 to 0.6881145685911179\n",
      "Model trained for 154 epochs out of 500. Training loss is 0.66629958152771\n",
      "Validation loss decreased from 0.6881145685911179 to 0.6879898756742477\n",
      "Model trained for 155 epochs out of 500. Training loss is 0.665846586227417\n",
      "Validation loss decreased from 0.6879898756742477 to 0.6878611296415329\n",
      "Model trained for 156 epochs out of 500. Training loss is 0.665381908416748\n",
      "Validation loss decreased from 0.6878611296415329 to 0.6877260506153107\n",
      "Model trained for 157 epochs out of 500. Training loss is 0.6649006605148315\n",
      "Validation loss decreased from 0.6877260506153107 to 0.6875950396060944\n",
      "Model trained for 158 epochs out of 500. Training loss is 0.6644084453582764\n",
      "Validation loss decreased from 0.6875950396060944 to 0.6874572187662125\n",
      "Model trained for 159 epochs out of 500. Training loss is 0.6639029383659363\n",
      "Validation loss decreased from 0.6874572187662125 to 0.6873152852058411\n",
      "Model trained for 160 epochs out of 500. Training loss is 0.663379430770874\n",
      "Validation loss decreased from 0.6873152852058411 to 0.6871698200702667\n",
      "Model trained for 161 epochs out of 500. Training loss is 0.6628373861312866\n",
      "Validation loss decreased from 0.6871698200702667 to 0.6870235204696655\n",
      "Model trained for 162 epochs out of 500. Training loss is 0.6622790098190308\n",
      "Validation loss decreased from 0.6870235204696655 to 0.6868705600500107\n",
      "Model trained for 163 epochs out of 500. Training loss is 0.6617221832275391\n",
      "Validation loss decreased from 0.6868705600500107 to 0.6867172420024872\n",
      "Model trained for 164 epochs out of 500. Training loss is 0.6611346006393433\n",
      "Validation loss decreased from 0.6867172420024872 to 0.6865580230951309\n",
      "Model trained for 165 epochs out of 500. Training loss is 0.6605435609817505\n",
      "Validation loss decreased from 0.6865580230951309 to 0.6863972693681717\n",
      "Model trained for 166 epochs out of 500. Training loss is 0.6599330902099609\n",
      "Validation loss decreased from 0.6863972693681717 to 0.6862309128046036\n",
      "Model trained for 167 epochs out of 500. Training loss is 0.6593139171600342\n",
      "Validation loss decreased from 0.6862309128046036 to 0.6860624402761459\n",
      "Model trained for 168 epochs out of 500. Training loss is 0.6586745977401733\n",
      "Validation loss decreased from 0.6860624402761459 to 0.685886338353157\n",
      "Model trained for 169 epochs out of 500. Training loss is 0.658046305179596\n",
      "Validation loss decreased from 0.685886338353157 to 0.6857045441865921\n",
      "Model trained for 170 epochs out of 500. Training loss is 0.6573798060417175\n",
      "Validation loss decreased from 0.6857045441865921 to 0.6855254471302032\n",
      "Model trained for 171 epochs out of 500. Training loss is 0.6566834449768066\n",
      "Validation loss decreased from 0.6855254471302032 to 0.6853381395339966\n",
      "Model trained for 172 epochs out of 500. Training loss is 0.6559624671936035\n",
      "Validation loss decreased from 0.6853381395339966 to 0.6851425319910049\n",
      "Model trained for 173 epochs out of 500. Training loss is 0.6552125215530396\n",
      "Validation loss decreased from 0.6851425319910049 to 0.6849430948495865\n",
      "Model trained for 174 epochs out of 500. Training loss is 0.6544443368911743\n",
      "Validation loss decreased from 0.6849430948495865 to 0.6847378760576248\n",
      "Model trained for 175 epochs out of 500. Training loss is 0.6536533832550049\n",
      "Validation loss decreased from 0.6847378760576248 to 0.6845232099294662\n",
      "Model trained for 176 epochs out of 500. Training loss is 0.652856707572937\n",
      "Validation loss decreased from 0.6845232099294662 to 0.6843068599700928\n",
      "Model trained for 177 epochs out of 500. Training loss is 0.6520361304283142\n",
      "Validation loss decreased from 0.6843068599700928 to 0.6840818375349045\n",
      "Model trained for 178 epochs out of 500. Training loss is 0.6512168645858765\n",
      "Validation loss decreased from 0.6840818375349045 to 0.6838489770889282\n",
      "Model trained for 179 epochs out of 500. Training loss is 0.6503576636314392\n",
      "Validation loss decreased from 0.6838489770889282 to 0.683607742190361\n",
      "Model trained for 180 epochs out of 500. Training loss is 0.6494349241256714\n",
      "Validation loss decreased from 0.683607742190361 to 0.6833656132221222\n",
      "Model trained for 181 epochs out of 500. Training loss is 0.648503839969635\n",
      "Validation loss decreased from 0.6833656132221222 to 0.6831155866384506\n",
      "Model trained for 182 epochs out of 500. Training loss is 0.6475489735603333\n",
      "Validation loss decreased from 0.6831155866384506 to 0.6828597635030746\n",
      "Model trained for 183 epochs out of 500. Training loss is 0.646546483039856\n",
      "Validation loss decreased from 0.6828597635030746 to 0.6826183199882507\n",
      "Model trained for 184 epochs out of 500. Training loss is 0.645516574382782\n",
      "Validation loss decreased from 0.6826183199882507 to 0.6823747605085373\n",
      "Model trained for 185 epochs out of 500. Training loss is 0.6444647312164307\n",
      "Validation loss decreased from 0.6823747605085373 to 0.6821194291114807\n",
      "Model trained for 186 epochs out of 500. Training loss is 0.6433794498443604\n",
      "Validation loss decreased from 0.6821194291114807 to 0.6818548738956451\n",
      "Model trained for 187 epochs out of 500. Training loss is 0.6422590613365173\n",
      "Validation loss decreased from 0.6818548738956451 to 0.6815877854824066\n",
      "Model trained for 188 epochs out of 500. Training loss is 0.6411219239234924\n",
      "Validation loss decreased from 0.6815877854824066 to 0.6813084036111832\n",
      "Model trained for 189 epochs out of 500. Training loss is 0.6399588584899902\n",
      "Validation loss decreased from 0.6813084036111832 to 0.6810182332992554\n",
      "Model trained for 190 epochs out of 500. Training loss is 0.6388018131256104\n",
      "Validation loss decreased from 0.6810182332992554 to 0.680717721581459\n",
      "Model trained for 191 epochs out of 500. Training loss is 0.6376089453697205\n",
      "Validation loss decreased from 0.680717721581459 to 0.6804160475730896\n",
      "Model trained for 192 epochs out of 500. Training loss is 0.636342465877533\n",
      "Validation loss decreased from 0.6804160475730896 to 0.6801174283027649\n",
      "Model trained for 193 epochs out of 500. Training loss is 0.6350445747375488\n",
      "Validation loss decreased from 0.6801174283027649 to 0.6798211187124252\n",
      "Model trained for 194 epochs out of 500. Training loss is 0.6337270140647888\n",
      "Validation loss decreased from 0.6798211187124252 to 0.6795142740011215\n",
      "Model trained for 195 epochs out of 500. Training loss is 0.6323474645614624\n",
      "Validation loss decreased from 0.6795142740011215 to 0.6791990101337433\n",
      "Model trained for 196 epochs out of 500. Training loss is 0.630916953086853\n",
      "Validation loss decreased from 0.6791990101337433 to 0.6788771152496338\n",
      "Model trained for 197 epochs out of 500. Training loss is 0.6294698715209961\n",
      "Validation loss decreased from 0.6788771152496338 to 0.6785317212343216\n",
      "Model trained for 198 epochs out of 500. Training loss is 0.627997875213623\n",
      "Validation loss decreased from 0.6785317212343216 to 0.6781688779592514\n",
      "Model trained for 199 epochs out of 500. Training loss is 0.6264702081680298\n",
      "Validation loss decreased from 0.6781688779592514 to 0.6777953654527664\n",
      "Model trained for 200 epochs out of 500. Training loss is 0.6248795390129089\n",
      "Validation loss decreased from 0.6777953654527664 to 0.6774093955755234\n",
      "Model trained for 201 epochs out of 500. Training loss is 0.6232554316520691\n",
      "Validation loss decreased from 0.6774093955755234 to 0.6770150512456894\n",
      "Model trained for 202 epochs out of 500. Training loss is 0.621576189994812\n",
      "Validation loss decreased from 0.6770150512456894 to 0.6766184419393539\n",
      "Model trained for 203 epochs out of 500. Training loss is 0.6198632121086121\n",
      "Validation loss decreased from 0.6766184419393539 to 0.6762224435806274\n",
      "Model trained for 204 epochs out of 500. Training loss is 0.6181217432022095\n",
      "Validation loss decreased from 0.6762224435806274 to 0.6758173108100891\n",
      "Model trained for 205 epochs out of 500. Training loss is 0.616331934928894\n",
      "Validation loss decreased from 0.6758173108100891 to 0.6754044890403748\n",
      "Model trained for 206 epochs out of 500. Training loss is 0.6144484877586365\n",
      "Validation loss decreased from 0.6754044890403748 to 0.6749909073114395\n",
      "Model trained for 207 epochs out of 500. Training loss is 0.6125071048736572\n",
      "Validation loss decreased from 0.6749909073114395 to 0.674570232629776\n",
      "Model trained for 208 epochs out of 500. Training loss is 0.610533595085144\n",
      "Validation loss decreased from 0.674570232629776 to 0.6741496175527573\n",
      "Model trained for 209 epochs out of 500. Training loss is 0.6084998846054077\n",
      "Validation loss decreased from 0.6741496175527573 to 0.673725351691246\n",
      "Model trained for 210 epochs out of 500. Training loss is 0.6064013838768005\n",
      "Validation loss decreased from 0.673725351691246 to 0.6732925921678543\n",
      "Model trained for 211 epochs out of 500. Training loss is 0.6042235493659973\n",
      "Validation loss decreased from 0.6732925921678543 to 0.6728343665599823\n",
      "Model trained for 212 epochs out of 500. Training loss is 0.6020192503929138\n",
      "Validation loss decreased from 0.6728343665599823 to 0.6723672151565552\n",
      "Model trained for 213 epochs out of 500. Training loss is 0.5997536182403564\n",
      "Validation loss decreased from 0.6723672151565552 to 0.6718892306089401\n",
      "Model trained for 214 epochs out of 500. Training loss is 0.5974130630493164\n",
      "Validation loss decreased from 0.6718892306089401 to 0.6714074164628983\n",
      "Model trained for 215 epochs out of 500. Training loss is 0.5950095057487488\n",
      "Validation loss decreased from 0.6714074164628983 to 0.6709396243095398\n",
      "Model trained for 216 epochs out of 500. Training loss is 0.59250807762146\n",
      "Validation loss decreased from 0.6709396243095398 to 0.6704652011394501\n",
      "Model trained for 217 epochs out of 500. Training loss is 0.5899550914764404\n",
      "Validation loss decreased from 0.6704652011394501 to 0.6699801683425903\n",
      "Model trained for 218 epochs out of 500. Training loss is 0.5872849225997925\n",
      "Validation loss decreased from 0.6699801683425903 to 0.6694979518651962\n",
      "Model trained for 219 epochs out of 500. Training loss is 0.5845905542373657\n",
      "Validation loss decreased from 0.6694979518651962 to 0.6690031290054321\n",
      "Model trained for 220 epochs out of 500. Training loss is 0.5817639231681824\n",
      "Validation loss decreased from 0.6690031290054321 to 0.668529748916626\n",
      "Model trained for 221 epochs out of 500. Training loss is 0.5788520574569702\n",
      "Validation loss decreased from 0.668529748916626 to 0.6680448204278946\n",
      "Model trained for 222 epochs out of 500. Training loss is 0.5758284330368042\n",
      "Validation loss decreased from 0.6680448204278946 to 0.667553037405014\n",
      "Model trained for 223 epochs out of 500. Training loss is 0.5727293491363525\n",
      "Validation loss decreased from 0.667553037405014 to 0.6670512855052948\n",
      "Model trained for 224 epochs out of 500. Training loss is 0.5695701837539673\n",
      "Validation loss decreased from 0.6670512855052948 to 0.6665241420269012\n",
      "Model trained for 225 epochs out of 500. Training loss is 0.5663499236106873\n",
      "Validation loss decreased from 0.6665241420269012 to 0.6659876704216003\n",
      "Model trained for 226 epochs out of 500. Training loss is 0.5631013512611389\n",
      "Validation loss decreased from 0.6659876704216003 to 0.6654387712478638\n",
      "Model trained for 227 epochs out of 500. Training loss is 0.5597964525222778\n",
      "Validation loss decreased from 0.6654387712478638 to 0.6648763418197632\n",
      "Model trained for 228 epochs out of 500. Training loss is 0.5563552379608154\n",
      "Validation loss decreased from 0.6648763418197632 to 0.664313405752182\n",
      "Model trained for 229 epochs out of 500. Training loss is 0.552830696105957\n",
      "Validation loss decreased from 0.664313405752182 to 0.6637345999479294\n",
      "Model trained for 230 epochs out of 500. Training loss is 0.5492104887962341\n",
      "Validation loss decreased from 0.6637345999479294 to 0.6631469279527664\n",
      "Model trained for 231 epochs out of 500. Training loss is 0.545547366142273\n",
      "Validation loss decreased from 0.6631469279527664 to 0.6625787019729614\n",
      "Model trained for 232 epochs out of 500. Training loss is 0.5418111681938171\n",
      "Validation loss decreased from 0.6625787019729614 to 0.6620001792907715\n",
      "Model trained for 233 epochs out of 500. Training loss is 0.5379809141159058\n",
      "Validation loss decreased from 0.6620001792907715 to 0.6614476293325424\n",
      "Model trained for 234 epochs out of 500. Training loss is 0.5340359210968018\n",
      "Validation loss decreased from 0.6614476293325424 to 0.6608643978834152\n",
      "Model trained for 235 epochs out of 500. Training loss is 0.5300204753875732\n",
      "Validation loss decreased from 0.6608643978834152 to 0.6603203117847443\n",
      "Model trained for 236 epochs out of 500. Training loss is 0.5259225368499756\n",
      "Validation loss decreased from 0.6603203117847443 to 0.6597542017698288\n",
      "Model trained for 237 epochs out of 500. Training loss is 0.5217219591140747\n",
      "Validation loss decreased from 0.6597542017698288 to 0.6591830402612686\n",
      "Model trained for 238 epochs out of 500. Training loss is 0.5174931287765503\n",
      "Validation loss decreased from 0.6591830402612686 to 0.658579871058464\n",
      "Model trained for 239 epochs out of 500. Training loss is 0.5131359696388245\n",
      "Validation loss decreased from 0.658579871058464 to 0.6579542756080627\n",
      "Model trained for 240 epochs out of 500. Training loss is 0.5086976289749146\n",
      "Validation loss decreased from 0.6579542756080627 to 0.6573475748300552\n",
      "Model trained for 241 epochs out of 500. Training loss is 0.5042106509208679\n",
      "Validation loss decreased from 0.6573475748300552 to 0.656756654381752\n",
      "Model trained for 242 epochs out of 500. Training loss is 0.4995884895324707\n",
      "Validation loss decreased from 0.656756654381752 to 0.6561661213636398\n",
      "Model trained for 243 epochs out of 500. Training loss is 0.49486392736434937\n",
      "Validation loss decreased from 0.6561661213636398 to 0.6555771976709366\n",
      "Model trained for 244 epochs out of 500. Training loss is 0.49004825949668884\n",
      "Validation loss decreased from 0.6555771976709366 to 0.6550034880638123\n",
      "Model trained for 245 epochs out of 500. Training loss is 0.4851484000682831\n",
      "Validation loss decreased from 0.6550034880638123 to 0.6544815897941589\n",
      "Model trained for 246 epochs out of 500. Training loss is 0.4802055060863495\n",
      "Validation loss decreased from 0.6544815897941589 to 0.653978019952774\n",
      "Model trained for 247 epochs out of 500. Training loss is 0.47517991065979004\n",
      "Validation loss decreased from 0.653978019952774 to 0.6534336060285568\n",
      "Model trained for 248 epochs out of 500. Training loss is 0.47011059522628784\n",
      "Validation loss decreased from 0.6534336060285568 to 0.6528933048248291\n",
      "Model trained for 249 epochs out of 500. Training loss is 0.464961975812912\n",
      "Validation loss decreased from 0.6528933048248291 to 0.6524336636066437\n",
      "Model trained for 250 epochs out of 500. Training loss is 0.4597786068916321\n",
      "Validation loss decreased from 0.6524336636066437 to 0.6520442366600037\n",
      "Model trained for 251 epochs out of 500. Training loss is 0.45450788736343384\n",
      "Validation loss decreased from 0.6520442366600037 to 0.6516375988721848\n",
      "Model trained for 252 epochs out of 500. Training loss is 0.44918569922447205\n",
      "Validation loss decreased from 0.6516375988721848 to 0.6512737572193146\n",
      "Model trained for 253 epochs out of 500. Training loss is 0.4438808560371399\n",
      "Validation loss decreased from 0.6512737572193146 to 0.6508861929178238\n",
      "Model trained for 254 epochs out of 500. Training loss is 0.4385041892528534\n",
      "Validation loss decreased from 0.6508861929178238 to 0.6505202054977417\n",
      "Model trained for 255 epochs out of 500. Training loss is 0.4330567717552185\n",
      "Validation loss decreased from 0.6505202054977417 to 0.6501714885234833\n",
      "Model trained for 256 epochs out of 500. Training loss is 0.42751455307006836\n",
      "Validation loss decreased from 0.6501714885234833 to 0.6498303860425949\n",
      "Model trained for 257 epochs out of 500. Training loss is 0.42194947600364685\n",
      "Validation loss decreased from 0.6498303860425949 to 0.649539440870285\n",
      "Model trained for 258 epochs out of 500. Training loss is 0.41639775037765503\n",
      "Validation loss decreased from 0.649539440870285 to 0.6492467373609543\n",
      "Model trained for 259 epochs out of 500. Training loss is 0.4107639789581299\n",
      "Validation loss decreased from 0.6492467373609543 to 0.6490051597356796\n",
      "Model trained for 260 epochs out of 500. Training loss is 0.4051137864589691\n",
      "Validation loss decreased from 0.6490051597356796 to 0.6487057209014893\n",
      "Model trained for 261 epochs out of 500. Training loss is 0.3993827700614929\n",
      "Validation loss decreased from 0.6487057209014893 to 0.6483483016490936\n",
      "Model trained for 262 epochs out of 500. Training loss is 0.3935527205467224\n",
      "Validation loss decreased from 0.6483483016490936 to 0.6480109989643097\n",
      "Model trained for 263 epochs out of 500. Training loss is 0.38766002655029297\n",
      "Validation loss decreased from 0.6480109989643097 to 0.647792398929596\n",
      "Model trained for 264 epochs out of 500. Training loss is 0.38177570700645447\n",
      "Validation loss decreased from 0.647792398929596 to 0.6475019752979279\n",
      "Model trained for 265 epochs out of 500. Training loss is 0.37587568163871765\n",
      "Validation loss decreased from 0.6475019752979279 to 0.6472156196832657\n",
      "Model trained for 266 epochs out of 500. Training loss is 0.36981305480003357\n",
      "Validation loss decreased from 0.6472156196832657 to 0.6469778120517731\n",
      "Model trained for 267 epochs out of 500. Training loss is 0.36370155215263367\n",
      "Validation loss decreased from 0.6469778120517731 to 0.6468263566493988\n",
      "Model trained for 268 epochs out of 500. Training loss is 0.35757431387901306\n",
      "Validation loss decreased from 0.6468263566493988 to 0.6467423737049103\n",
      "Model trained for 269 epochs out of 500. Training loss is 0.3514626622200012\n",
      "Validation loss decreased from 0.6467423737049103 to 0.6466554403305054\n",
      "Model trained for 270 epochs out of 500. Training loss is 0.34539324045181274\n",
      "Validation loss decreased from 0.6466554403305054 to 0.6466054618358612\n",
      "Model trained for 271 epochs out of 500. Training loss is 0.3393014073371887\n",
      "Validation loss decreased from 0.6466054618358612 to 0.6464608162641525\n",
      "Model trained for 272 epochs out of 500. Training loss is 0.3332439959049225\n",
      "Validation loss decreased from 0.6464608162641525 to 0.6462629288434982\n",
      "Model trained for 273 epochs out of 500. Training loss is 0.32721054553985596\n",
      "Validation loss decreased from 0.6462629288434982 to 0.6460237056016922\n",
      "Model trained for 274 epochs out of 500. Training loss is 0.3211217224597931\n",
      "Validation loss decreased from 0.6460237056016922 to 0.6457693576812744\n",
      "Model trained for 275 epochs out of 500. Training loss is 0.31501489877700806\n",
      "Validation loss decreased from 0.6457693576812744 to 0.645457997918129\n",
      "Model trained for 276 epochs out of 500. Training loss is 0.30885887145996094\n",
      "Validation loss decreased from 0.645457997918129 to 0.6450406461954117\n",
      "Model trained for 277 epochs out of 500. Training loss is 0.30285805463790894\n",
      "Validation loss decreased from 0.6450406461954117 to 0.6446237415075302\n",
      "Model trained for 278 epochs out of 500. Training loss is 0.2968931794166565\n",
      "Validation loss decreased from 0.6446237415075302 to 0.6442082822322845\n",
      "Model trained for 279 epochs out of 500. Training loss is 0.2909925580024719\n",
      "Validation loss decreased from 0.6442082822322845 to 0.6438537240028381\n",
      "Model trained for 280 epochs out of 500. Training loss is 0.2852087616920471\n",
      "Validation loss decreased from 0.6438537240028381 to 0.6433678418397903\n",
      "Model trained for 281 epochs out of 500. Training loss is 0.27945491671562195\n",
      "Validation loss decreased from 0.6433678418397903 to 0.6430600136518478\n",
      "Model trained for 282 epochs out of 500. Training loss is 0.2736929655075073\n",
      "Validation loss decreased from 0.6430600136518478 to 0.6427894234657288\n",
      "Model trained for 283 epochs out of 500. Training loss is 0.26800888776779175\n",
      "Validation loss decreased from 0.6427894234657288 to 0.6426064223051071\n",
      "Model trained for 284 epochs out of 500. Training loss is 0.26227301359176636\n",
      "Validation loss decreased from 0.6426064223051071 to 0.6424933969974518\n",
      "Model trained for 285 epochs out of 500. Training loss is 0.2566315829753876\n",
      "Counter for early stopping: 1 out of 50\n",
      "Model trained for 286 epochs out of 500. Training loss is 0.25106263160705566\n",
      "Counter for early stopping: 2 out of 50\n",
      "Model trained for 287 epochs out of 500. Training loss is 0.24557921290397644\n",
      "Counter for early stopping: 3 out of 50\n",
      "Model trained for 288 epochs out of 500. Training loss is 0.24013343453407288\n",
      "Counter for early stopping: 4 out of 50\n",
      "Model trained for 289 epochs out of 500. Training loss is 0.23488114774227142\n",
      "Counter for early stopping: 5 out of 50\n",
      "Model trained for 290 epochs out of 500. Training loss is 0.22972500324249268\n",
      "Counter for early stopping: 6 out of 50\n",
      "Model trained for 291 epochs out of 500. Training loss is 0.22465774416923523\n",
      "Counter for early stopping: 7 out of 50\n",
      "Model trained for 292 epochs out of 500. Training loss is 0.21968838572502136\n",
      "Counter for early stopping: 8 out of 50\n",
      "Model trained for 293 epochs out of 500. Training loss is 0.21475699543952942\n",
      "Counter for early stopping: 9 out of 50\n",
      "Model trained for 294 epochs out of 500. Training loss is 0.20999257266521454\n",
      "Counter for early stopping: 10 out of 50\n",
      "Model trained for 295 epochs out of 500. Training loss is 0.20542117953300476\n",
      "Counter for early stopping: 11 out of 50\n",
      "Model trained for 296 epochs out of 500. Training loss is 0.200962632894516\n",
      "Counter for early stopping: 12 out of 50\n",
      "Model trained for 297 epochs out of 500. Training loss is 0.19670379161834717\n",
      "Counter for early stopping: 13 out of 50\n",
      "Model trained for 298 epochs out of 500. Training loss is 0.19246506690979004\n",
      "Counter for early stopping: 14 out of 50\n",
      "Model trained for 299 epochs out of 500. Training loss is 0.18836747109889984\n",
      "Counter for early stopping: 15 out of 50\n",
      "Model trained for 300 epochs out of 500. Training loss is 0.18434616923332214\n",
      "Counter for early stopping: 16 out of 50\n",
      "Model trained for 301 epochs out of 500. Training loss is 0.18037013709545135\n",
      "Counter for early stopping: 17 out of 50\n",
      "Model trained for 302 epochs out of 500. Training loss is 0.17651528120040894\n",
      "Counter for early stopping: 18 out of 50\n",
      "Model trained for 303 epochs out of 500. Training loss is 0.172737717628479\n",
      "Counter for early stopping: 19 out of 50\n",
      "Model trained for 304 epochs out of 500. Training loss is 0.16910353302955627\n",
      "Counter for early stopping: 20 out of 50\n",
      "Model trained for 305 epochs out of 500. Training loss is 0.16549766063690186\n",
      "Counter for early stopping: 21 out of 50\n",
      "Model trained for 306 epochs out of 500. Training loss is 0.16206403076648712\n",
      "Counter for early stopping: 22 out of 50\n",
      "Model trained for 307 epochs out of 500. Training loss is 0.1587620973587036\n",
      "Counter for early stopping: 23 out of 50\n",
      "Model trained for 308 epochs out of 500. Training loss is 0.15543857216835022\n",
      "Counter for early stopping: 24 out of 50\n",
      "Model trained for 309 epochs out of 500. Training loss is 0.1521856188774109\n",
      "Counter for early stopping: 25 out of 50\n",
      "Model trained for 310 epochs out of 500. Training loss is 0.14893841743469238\n",
      "Counter for early stopping: 26 out of 50\n",
      "Model trained for 311 epochs out of 500. Training loss is 0.1459302008152008\n",
      "Counter for early stopping: 27 out of 50\n",
      "Model trained for 312 epochs out of 500. Training loss is 0.1429823637008667\n",
      "Counter for early stopping: 28 out of 50\n",
      "Model trained for 313 epochs out of 500. Training loss is 0.1401047706604004\n",
      "Counter for early stopping: 29 out of 50\n",
      "Model trained for 314 epochs out of 500. Training loss is 0.13727104663848877\n",
      "Counter for early stopping: 30 out of 50\n",
      "Model trained for 315 epochs out of 500. Training loss is 0.13456052541732788\n",
      "Counter for early stopping: 31 out of 50\n",
      "Model trained for 316 epochs out of 500. Training loss is 0.13192079961299896\n",
      "Counter for early stopping: 32 out of 50\n",
      "Model trained for 317 epochs out of 500. Training loss is 0.1293855607509613\n",
      "Counter for early stopping: 33 out of 50\n",
      "Model trained for 318 epochs out of 500. Training loss is 0.12686410546302795\n",
      "Counter for early stopping: 34 out of 50\n",
      "Model trained for 319 epochs out of 500. Training loss is 0.12442349642515182\n",
      "Counter for early stopping: 35 out of 50\n",
      "Model trained for 320 epochs out of 500. Training loss is 0.1220783218741417\n",
      "Counter for early stopping: 36 out of 50\n",
      "Model trained for 321 epochs out of 500. Training loss is 0.1197703406214714\n",
      "Counter for early stopping: 37 out of 50\n",
      "Model trained for 322 epochs out of 500. Training loss is 0.11746010184288025\n",
      "Counter for early stopping: 38 out of 50\n",
      "Model trained for 323 epochs out of 500. Training loss is 0.11512341350317001\n",
      "Counter for early stopping: 39 out of 50\n",
      "Model trained for 324 epochs out of 500. Training loss is 0.11282487213611603\n",
      "Counter for early stopping: 40 out of 50\n",
      "Model trained for 325 epochs out of 500. Training loss is 0.11060361564159393\n",
      "Counter for early stopping: 41 out of 50\n",
      "Model trained for 326 epochs out of 500. Training loss is 0.10849446058273315\n",
      "Counter for early stopping: 42 out of 50\n",
      "Model trained for 327 epochs out of 500. Training loss is 0.1064431369304657\n",
      "Counter for early stopping: 43 out of 50\n",
      "Model trained for 328 epochs out of 500. Training loss is 0.10437428206205368\n",
      "Counter for early stopping: 44 out of 50\n",
      "Model trained for 329 epochs out of 500. Training loss is 0.10252231359481812\n",
      "Counter for early stopping: 45 out of 50\n",
      "Model trained for 330 epochs out of 500. Training loss is 0.1006380021572113\n",
      "Counter for early stopping: 46 out of 50\n",
      "Model trained for 331 epochs out of 500. Training loss is 0.09882204979658127\n",
      "Counter for early stopping: 47 out of 50\n",
      "Model trained for 332 epochs out of 500. Training loss is 0.09705093502998352\n",
      "Counter for early stopping: 48 out of 50\n",
      "Model trained for 333 epochs out of 500. Training loss is 0.09532438218593597\n",
      "Counter for early stopping: 49 out of 50\n",
      "Model trained for 334 epochs out of 500. Training loss is 0.09367279708385468\n",
      "Counter for early stopping: 50 out of 50\n",
      "early stopping at epoch  284\n"
     ]
    }
   ],
   "source": [
    "verbose=True\n",
    "num_motif=120\n",
    "motif_len=24\n",
    "sigma_conv=10**-3\n",
    "sigma_w=0.1\n",
    "num_conv_layers = 1\n",
    "dropprob = 0.2\n",
    "l_rate=0.001\n",
    "maxepochs,epochs_for_early_stop = 500,50\n",
    "model = Network(num_motif, motif_len).to(device)#num_conv_layers,dropprob\n",
    "best_model,epochs,train_losses,valid_losses = Train_model(model,train_loader,valid_loader,l_rate ,maxepochs,epochs_for_early_stop,verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test data  0.8485119047619049\n"
     ]
    }
   ],
   "source": [
    "auc = Test_model(best_model,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
