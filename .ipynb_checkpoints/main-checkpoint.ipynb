{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea054c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math \n",
    "import random\n",
    "import gzip\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from torch import einsum\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc92a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weblogo_opts = '-X NO -Y NO --errorbars NO --fineprint \"\"'\n",
    "weblogo_opts = '-X NO --fineprint \"\"'\n",
    "weblogo_opts += ' -C \"#CB2026\" A A'\n",
    "weblogo_opts += ' -C \"#34459C\" C C'\n",
    "weblogo_opts += ' -C \"#FBB116\" G G'\n",
    "# embed\n",
    "weblogo_opts += ' -C \"#0C8040\" T T'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e64639",
   "metadata": {},
   "source": [
    "# DATA Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ff4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chrom_train_test(peaks,Chr_dict):\n",
    "    peak_chromosomes = {}\n",
    "    n_peaks = 0\n",
    "    chrom_train = []\n",
    "    chrom_test = []\n",
    "    for line in peaks:\n",
    "        split_line = 'chromosome='+line.split('\\t')[0]\n",
    "        peak_chromosomes[split_line] = peak_chromosomes.get(split_line,0) + 1\n",
    "        n_peaks+=1\n",
    "    n_peaks-=peak_chromosomes.pop('chromosome=pombeIII')\n",
    "    size_test = int(n_peaks/10)\n",
    "    npeaks_test = 0\n",
    "    while npeaks_test<size_test:\n",
    "        chrom = random.choice(list(Chr_dict.keys()))\n",
    "        npeaks_test += peak_chromosomes[chrom]\n",
    "        chrom_test.append(chrom)\n",
    "        if npeaks_test>int(n_peaks*1.3/10):\n",
    "            npeaks_test = 0\n",
    "            chrom_test = []\n",
    "    for chrom in Chr_dict.keys():\n",
    "        if chrom not in chrom_test:\n",
    "            chrom_train.append(chrom)\n",
    "    return chrom_train,chrom_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4831bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genome_data(data_file):\n",
    "    data=open(data_file).read()\n",
    "    chromosomes_data = data.split('>')[1:]\n",
    "    return (chromosomes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a84bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_bed_file(chromosomes_data,peak_file,seq_length,Chr_dict,cross_chrom):\n",
    "    peaks = open(peak_file).readlines()\n",
    "    peak_sequences = []\n",
    "    if cross_chrom:\n",
    "        peak_sequences_train,peak_sequences_test = [],[]\n",
    "        chrom_train , chrom_test = generate_chrom_train_test(peaks,Chr_dict)\n",
    "    for peak in peaks:\n",
    "        peak_split = peak.split('\\t')\n",
    "        Chr = 'chromosome='+str(peak_split[0])\n",
    "        if Chr in Chr_dict:\n",
    "            chrom_seq = Chr_dict[Chr]\n",
    "            n = len(chrom_seq)\n",
    "            start_idx = max(int(peak_split[1])-seq_length//2,0)\n",
    "            end_idx = min(int(len(chrom_seq)), start_idx+seq_length)\n",
    "            if end_idx == len(chrom_seq):\n",
    "                start_idx = end_idx - seq_length\n",
    "            header = Chr+':{0}-{1}'.format(start_idx,end_idx)\n",
    "            if not cross_chrom:\n",
    "                peak_sequences.append([header,chrom_seq[start_idx:end_idx]])\n",
    "            else:\n",
    "                if Chr in chrom_train:\n",
    "                    peak_sequences_train.append([header,chrom_seq[start_idx:end_idx]])\n",
    "                else:\n",
    "                    peak_sequences_test.append([header,chrom_seq[start_idx:end_idx]])\n",
    "    if not cross_chrom:\n",
    "        size=int(len(peak_sequences)/10)\n",
    "        peak_sequences_train = peak_sequences[:9*size]\n",
    "        peak_sequences_test = peak_sequences[9*size:]\n",
    "    return (peak_sequences_train,peak_sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d07964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dinucshuffle(sequence):\n",
    "    b=[sequence[i:i+2] for i in range(0, len(sequence), 2)]\n",
    "    random.shuffle(b)\n",
    "    d=''.join([str(x) for x in b])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "584b788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqtopad(sequence, motif_len):\n",
    "    rows=len(sequence)+2*motif_len-2\n",
    "    S=np.empty([rows,4])\n",
    "    base=['A', 'C', 'G', 'T']\n",
    "    for i in range(rows):\n",
    "        for j in range(4):\n",
    "            if (i-motif_len+1<len(sequence) and sequence[i-motif_len+1]=='N' \n",
    "                or i<motif_len-1 or i>len(sequence)+motif_len-2):\n",
    "                S[i,j]=np.float32(0.25)\n",
    "            elif sequence[i-motif_len+1]==base[j]:\n",
    "                S[i,j]=np.float32(1)\n",
    "            else:\n",
    "                S[i,j]=np.float32(0)\n",
    "    return np.transpose(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b0f38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_onehot_data(peak_sequences,motif_length,label,include_dinuc):\n",
    "    alldata = []\n",
    "    for header,seq in peak_sequences:\n",
    "        alldata.append([header,seq,seqtopad(seq,motif_length),[int(label)]])#\n",
    "        if include_dinuc:\n",
    "            shuff_seq = dinucshuffle(seq)\n",
    "            alldata.append([header,shuff_seq,seqtopad(shuff_seq,motif_length),[0]])#\n",
    "    return (alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d582c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data_file,peak_file,motif_length=24,seq_length=150,cross_chrom=False,include_dinuc=True,Chr_dict=None):\n",
    "    chromosomes_data = genome_data(data_file)\n",
    "    if Chr_dict==None:\n",
    "        Chr_dict = {}\n",
    "        for chrom_data in chromosomes_data:\n",
    "            ref = chrom_data.split('\\n')[0].split(' ')[-1][1:-1]\n",
    "            Chr_dict[ref]=''.join(chrom_data.split('\\n')[1:])\n",
    "        Chr_dict['chromosome=Mito'] = Chr_dict.pop('top=circular')\n",
    "    if type(peak_file) == str:\n",
    "        peak_sequences_train,peak_sequences_test = Read_bed_file(chromosomes_data,peak_file,seq_length,Chr_dict,cross_chrom)\n",
    "        train_data = generate_onehot_data(peak_sequences_train,motif_length,1,include_dinuc)\n",
    "        test_data = generate_onehot_data(peak_sequences_test,motif_length,1,include_dinuc)\n",
    "        random.shuffle(train_data)\n",
    "        size=int(len(train_data)/10)\n",
    "        calib_data=train_data[:9*size]\n",
    "        valid_data=train_data[9*size:]\n",
    "    elif type(peak_file) == list:\n",
    "        include_dinuc = False\n",
    "        peak_sequences_train,peak_sequences_test = [],[]\n",
    "        train_data,test_data = [],[]\n",
    "        for i in range (len(peak_file)):\n",
    "            peak_sequences_train_temp,peak_sequences_test_temp = Read_bed_file(chromosomes_data,peak_file[i],seq_length,Chr_dict,cross_chrom)\n",
    "            peak_sequences_train.extend(peak_sequences_train_temp)\n",
    "            peak_sequences_test.extend(peak_sequences_test_temp)\n",
    "            train_data.extend(generate_onehot_data(peak_sequences_train_temp,motif_length,i,include_dinuc))\n",
    "            test_data.extend(generate_onehot_data(peak_sequences_test_temp,motif_length,i,include_dinuc))\n",
    "        random.shuffle(train_data)\n",
    "        random.shuffle(test_data)\n",
    "        size=int(len(train_data)/10)\n",
    "        calib_data=train_data[:9*size]\n",
    "        valid_data=train_data[9*size:]\n",
    "    return calib_data,valid_data,train_data,test_data,peak_sequences_train,peak_sequences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c6057d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, xy=None):\n",
    "        self.header=[el[0] for el in xy]\n",
    "        self.seq =[el[1] for el in xy ]\n",
    "        self.x_data=np.asarray([el[2] for el in xy],dtype=np.float32)\n",
    "        self.y_data =np.asarray([el[3] for el in xy ],dtype=np.float32)\n",
    "        self.x_data = torch.from_numpy(self.x_data)\n",
    "        self.y_data = torch.from_numpy(self.y_data)\n",
    "        self.length=len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.header[index],self.seq[index],self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef79b14",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70a7e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPool(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.to_attn_logits = nn.Parameter(torch.eye(dim)) \n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_logits = einsum('b n d, d e -> b n e', x, self.to_attn_logits) \n",
    "        attn = attn_logits.softmax(dim = -2) \n",
    "        return (x * attn).sum(dim = -2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e31aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, num_motif , motif_len , num_conv_layers , dropprob):\n",
    "        super(Network, self).__init__()\n",
    "        self.num_motif = num_motif\n",
    "        self.conv = [nn.Conv1d(4, num_motif, kernel_size=motif_len),nn.ReLU(inplace=True)]\n",
    "        in_channels = num_motif\n",
    "        for i in range (num_conv_layers-1):\n",
    "            motif_len = motif_len//2\n",
    "            self.conv.append(nn.MaxPool1d(kernel_size=3))\n",
    "            self.conv.append(nn.Conv1d(in_channels, int(1.5*in_channels), kernel_size=motif_len))\n",
    "            self.conv.append(nn.ReLU(inplace=True))\n",
    "            in_channels = int(1.5*in_channels)\n",
    "        self.conv_layer = nn.Sequential(*self.conv)\n",
    "        self.project = AttentionPool(in_channels)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_channels , in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropprob, inplace=False),\n",
    "            nn.Linear(in_channels, 1),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x= x.permute(0, 2, 1)\n",
    "        x = self.project(x)\n",
    "        predict = self.classifier(x)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb2ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_output(nn.Module):\n",
    "    def __init__(self,filter_weights,filter_bias,device):\n",
    "        super(conv_output, self).__init__()\n",
    "        if type(filter_weights) is np.ndarray:\n",
    "            self.filter_weights =  torch.from_numpy(filter_weights.astype(np.float32)).to(device)\n",
    "        else :\n",
    "            self.filter_weights = filter_weights.to(device)\n",
    "        if type(filter_bias) is np.ndarray:\n",
    "            self.filter_bias =  torch.from_numpy(filter_bias.astype(np.float32)).to(device)\n",
    "        else :\n",
    "            self.filter_bias = filter_bias.to(device)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.conv1d(x, self.filter_weights, bias=self.filter_bias, stride=1, padding=0)\n",
    "        out=x.clamp(min=0)\n",
    "        return (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0649a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### printing parameters ------------------\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table.get_string())\n",
    "    print(f\"\\n Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d6ce6",
   "metadata": {},
   "source": [
    "# Calib - Train - Test functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "79573514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_model(model,train_loader,valid_loader, l_rate=0.01 , maxepochs=100,epochs_for_early_stop=0,save_model=False):\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "    counter = 0\n",
    "    nepochs=0\n",
    "    valid_losses =[]\n",
    "    train_losses = []\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=l_rate,weight_decay=1e-05)\n",
    "    criterion = nn.BCELoss(reduction='mean')\n",
    "    while nepochs<maxepochs:\n",
    "        model.train()\n",
    "        train_loss=0\n",
    "        for i, (header, seq, data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)#\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "        if verbose:\n",
    "            print('Model trained for {0} epochs out of {2}. Training loss is {1}'.format(nepochs+1,loss.item(),maxepochs))\n",
    "        train_losses.append(train_loss/(i+1))\n",
    "        with torch.no_grad():\n",
    "            model.eval() \n",
    "            valid_loss=0\n",
    "            for i, (header, seq, data, target) in enumerate(valid_loader):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = F.binary_cross_entropy(output, target)#\n",
    "                valid_loss+=loss.item()\n",
    "            valid_losses.append(valid_loss/(i+1))\n",
    "        counter+=1\n",
    "        nepochs +=1\n",
    "        if epochs_for_early_stop>0:\n",
    "            if valid_losses[-1]<best_loss:\n",
    "                if verbose:\n",
    "                    print('Validation loss decreased from {0} to {1}'.format(best_loss,valid_losses[-1]))\n",
    "                best_loss = valid_losses[-1]\n",
    "                best_model = model\n",
    "                counter = 0\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('Counter for early stopping: {0} out of {1}'.format(counter,epochs_for_early_stop))\n",
    "                if counter == epochs_for_early_stop:\n",
    "                    print('early stopping at epoch ', nepochs-counter)\n",
    "                    if save_model:\n",
    "                        torch.save(best_model,model_dir+'/best_model.pkl')\n",
    "                        count_parameters(best_model)\n",
    "                    return (best_model,nepochs-counter,train_losses,valid_losses)\n",
    "    print('no early stopping')\n",
    "    if save_model:\n",
    "        torch.save(model,model_dir+'/best_model.pkl')\n",
    "        count_parameters(model)\n",
    "    return (model,nepochs,train_losses,valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88e481f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_model(model,test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        pred_list = []\n",
    "        labels_list = []\n",
    "        for i, (header, seq, data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
    "            labels=target.cpu().numpy().reshape(output.shape[0])\n",
    "            pred_list.append(pred)\n",
    "            labels_list.append(labels)\n",
    "        labels = np.concatenate(labels_list)\n",
    "        predictions = np.concatenate(pred_list)\n",
    "    auc = metrics.roc_auc_score(labels, predictions)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(labels, predictions)\n",
    "    prc = (metrics.auc(recall, precision))\n",
    "    if verbose:\n",
    "        print('AUROC on test data ', auc)\n",
    "        print('AUPRC on test data ', prc)\n",
    "    return (auc,prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3e24718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calibrate_model(calib_loader,valid_loader, num_motif_list, num_conv_layers_list , dropprob_list,learning_rate_list, \n",
    "                    max_num_models=40, maxepochs=100,epochs_for_early_stop=0 , motif_len=24 ):\n",
    "    results=pd.DataFrame(columns=['num_conv_layers','num_motif','Dropout','Learning Rate','epochs','AUROC','AUPRC'])\n",
    "    best_AUC = 0\n",
    "    if verbose:\n",
    "        print('Training on ',device)\n",
    "    for number in range(max_num_models):\n",
    "        print('model {0} out of {1}'.format(number+1,max_num_models))\n",
    "        # hyper-parameters\n",
    "        num_motif = random.choice(num_motif_list)\n",
    "        num_conv_layers = random.choice(num_conv_layers_list)\n",
    "        dropprob = random.choice(dropprob_list)\n",
    "        l_rate = random.choice(learning_rate_list)\n",
    "        while ((results['num_conv_layers']==num_conv_layers) & (results['num_motif']==num_motif) \n",
    "               & (results['Dropout']==dropprob) & (results['Learning Rate']==l_rate)).any(): \n",
    "            #if hyperparameters exist in the results dataframe then randomly choose other parameters\n",
    "            num_motif = random.choice(num_motif_list)\n",
    "            num_conv_layers = random.choice(num_conv_layers_list)\n",
    "            dropprob = random.choice(dropprob_list)\n",
    "            l_rate = random.choice(learning_rate_list)\n",
    "        model = Network(num_motif , motif_len , num_conv_layers , dropprob).to(device)#num_conv_layers,dropprob\n",
    "        best_model,epochs,train_losses,valid_losses = Train_model(model,calib_loader,valid_loader,l_rate ,maxepochs,epochs_for_early_stop)\n",
    "        auc,prc = Test_model(best_model,valid_loader)\n",
    "        results=pd.concat([results,pd.DataFrame({'num_conv_layers':num_conv_layers,'num_motif':num_motif,'Dropout':dropprob,\n",
    "                                                 'Learning Rate':l_rate,'epochs':epochs,'AUROC':[auc],'AUPRC':[prc]})])\n",
    "        if auc > best_AUC :\n",
    "            best_AUC = auc\n",
    "            best_epochs = epochs\n",
    "            best_num_motif = num_motif\n",
    "            best_num_conv_layers = num_conv_layers\n",
    "            best_dropprob = dropprob\n",
    "            best_l_rate = l_rate\n",
    "    best_hyperparameters = {'best_epochs': best_epochs,'best_num_motif':best_num_motif,\n",
    "                            'best_num_conv_layers':best_num_conv_layers,'best_dropprob':best_dropprob,'best_l_rate':best_l_rate}\n",
    "    torch.save(best_hyperparameters, model_dir+'/best_hyperpamarameters.pth')\n",
    "    results.sort_values(by='AUROC',ascending=False,inplace=True)\n",
    "    results.to_csv(model_dir+'/calibration_df.csv',index=False)\n",
    "    return best_hyperparameters,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c32a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_filter_outputs(model,test_loader):\n",
    "    with torch.no_grad():\n",
    "        best_model.eval()\n",
    "        pred_list = []\n",
    "        for i, (header, seq, data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred=output.cpu().detach().numpy()\n",
    "            pred_list.append(pred)\n",
    "        predictions = np.concatenate(pred_list)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532222b",
   "metadata": {},
   "source": [
    "# Motif extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ebd21d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_content(pwm, transpose=False, bg_gc=0.415):\n",
    "    ''' Compute PWM information content.\n",
    "    In the original analysis, I used a bg_gc=0.5. For any\n",
    "    future analysis, I ought to switch to the true hg19\n",
    "    value of 0.415.\n",
    "    '''\n",
    "    pseudoc = 1e-9\n",
    "    if transpose:\n",
    "        pwm = np.transpose(pwm)\n",
    "\n",
    "    bg_pwm = [1-bg_gc, bg_gc, bg_gc, 1-bg_gc]\n",
    "\n",
    "    ic = 0\n",
    "    for i in range(pwm.shape[0]):\n",
    "        for j in range(4):\n",
    "            # ic += 0.5 + pwm[i][j]*np.log2(pseudoc+pwm[i][j])\n",
    "            ic += -bg_pwm[j]*np.log2(bg_pwm[j]) + pwm[i][j]*np.log2(pseudoc+pwm[i][j])\n",
    "    return ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76c17aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meme_intro(meme_file, seqs):\n",
    "    ''' Open MEME motif format file and print intro\n",
    "    Attrs:\n",
    "        meme_file (str) : filename\n",
    "        seqs [str] : list of strings for obtaining background freqs\n",
    "    Returns:\n",
    "        mem_out : open MEME file\n",
    "    '''\n",
    "    nts = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "\n",
    "    # count\n",
    "    nt_counts = [1]*4\n",
    "    for i in range(len(seqs)):\n",
    "        for nt in seqs[i][1]:\n",
    "            try:\n",
    "                nt_counts[nts[nt]] += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    # normalize\n",
    "    nt_sum = float(sum(nt_counts))\n",
    "    nt_freqs = [nt_counts[i]/nt_sum for i in range(4)]\n",
    "\n",
    "    # open file for writing\n",
    "    meme_out = open(meme_file, 'w')\n",
    "\n",
    "    # print intro material\n",
    "    print( 'MEME version 4', file=meme_out)\n",
    "    print( '', file=meme_out)\n",
    "    #embd\n",
    "\n",
    "    print( 'ALPHABET= ACGT', file=meme_out)        \n",
    "    \n",
    "    print( '', file=meme_out)\n",
    "    print( 'Background letter frequencies:', file=meme_out)\n",
    "    #embd\n",
    "    print( 'A %.4f C %.4f G %.4f T %.4f' % tuple(nt_freqs), file=meme_out)\n",
    "    print( '', file=meme_out)\n",
    "    return meme_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d58a1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter_pwm(filter_fasta):\n",
    "    ''' Make a PWM for this filter from its top hits '''\n",
    "    nts = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "    #embd\n",
    "    pwm_counts = []\n",
    "    nsites = 4 # pseudocounts\n",
    "    for line in open(filter_fasta):\n",
    "        if line[0] != '>':\n",
    "            seq = line.rstrip()\n",
    "            nsites += 1\n",
    "            if len(pwm_counts) == 0:\n",
    "                # initialize with the length\n",
    "                for i in range(len(seq)):\n",
    "                    pwm_counts.append(np.array([1.0]*4))\n",
    "\n",
    "            # count\n",
    "            for i in range(len(seq)):\n",
    "                try:\n",
    "                    pwm_counts[i][nts[seq[i]]] += 1\n",
    "                except KeyError:\n",
    "                    pwm_counts[i] += np.array([0.25]*4)\n",
    "\n",
    "    # normalize\n",
    "    pwm_freqs = []\n",
    "    for i in range(len(pwm_counts)):\n",
    "        pwm_freqs.append([pwm_counts[i][j]/float(nsites) for j in range(4)])\n",
    "\n",
    "    return np.array(pwm_freqs), nsites-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58673d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_density(f_scores, out_pdf):\n",
    "    sns.set(font_scale=1.3)\n",
    "    plt.figure()\n",
    "    sns.distplot(f_scores, kde=False)\n",
    "    plt.xlabel('ReLU output')\n",
    "    plt.savefig(out_pdf)\n",
    "    plt.close()\n",
    "\n",
    "    return f_scores.mean(), f_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "948f58b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_motif(param_matrix):\n",
    "    nts = 'ACGT'\n",
    "    motif_list = []\n",
    "    for v in range(param_matrix.shape[1]):\n",
    "        max_n = 0\n",
    "        for n in range(1,4):\n",
    "            if param_matrix[n,v] > param_matrix[max_n,v]:\n",
    "                max_n = n\n",
    "\n",
    "        if param_matrix[max_n,v] > 0:\n",
    "            motif_list.append(nts[max_n])\n",
    "        else:\n",
    "            motif_list.append('N')\n",
    "\n",
    "    return ''.join(motif_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc48f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filter_heat(param_matrix, out_pdf):\n",
    "    param_range = abs(param_matrix).max()\n",
    "\n",
    "    sns.set(font_scale=2)\n",
    "    plt.figure(figsize=(param_matrix.shape[1], 4))\n",
    "    sns.heatmap(param_matrix, cmap='PRGn', linewidths=0.2, vmin=-param_range, vmax=param_range)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels(range(1,param_matrix.shape[1]+1))\n",
    "    ax.set_yticklabels('ACGT', rotation='horizontal') # , size=10)\n",
    "    plt.savefig(out_pdf)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cebfb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filter_logo(filter_outs, filter_size, seqs, out_prefix, filter_num, raw_t=0, maxpct_t=None):\n",
    "    if maxpct_t:\n",
    "        all_outs = np.ravel(filter_outs)\n",
    "        all_outs_mean = all_outs.mean()\n",
    "        all_outs_norm = all_outs - all_outs_mean\n",
    "        raw_t = maxpct_t * all_outs_norm.max() + all_outs_mean\n",
    "    # print fasta file of positive outputs\n",
    "    filter_fasta_out = open('%s.fa' % out_prefix, 'w')\n",
    "    filter_count = 0\n",
    "    for i in range(filter_outs.shape[0]):\n",
    "        for j in range(filter_outs.shape[1]):\n",
    "            if filter_outs[i,j] > raw_t:\n",
    "                kmer = seqs[i][1][j:j+filter_size]\n",
    "                chrom = motif_sequences[i][0].split(':')[0]\n",
    "                pos = int(motif_sequences[i][0].split(':')[1].split('-')[0])+j\n",
    "                try:\n",
    "                    filter_hits[filter_num][chrom].append(pos)\n",
    "                except:\n",
    "                    filter_hits[filter_num][chrom] = [pos]\n",
    "                #kmer = kmer.replace('T','U')\n",
    "                incl_kmer = len(kmer) - kmer.count('N')\n",
    "                if incl_kmer <filter_size:\n",
    "                    continue\n",
    "                print('>%d_%d' % (i,j), file=filter_fasta_out)\n",
    "                print(kmer, file=filter_fasta_out)\n",
    "                filter_count += 1\n",
    "    filter_fasta_out.close()\n",
    "    # make weblogo\n",
    "    if filter_count > 0:\n",
    "        weblogo_cmd = 'weblogo %s < %s.fa > %s.eps' % (weblogo_opts, out_prefix, out_prefix)\n",
    "        subprocess.call(weblogo_cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5465afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meme_add(meme_out, f, filter_pwm, nsites, trim_filters=False):\n",
    "    ''' Print a filter to the growing MEME file\n",
    "    Attrs:\n",
    "        meme_out : open file\n",
    "        f (int) : filter index #\n",
    "        filter_pwm (array) : filter PWM array\n",
    "        nsites (int) : number of filter sites\n",
    "    '''\n",
    "    if not trim_filters:\n",
    "        ic_start = 0\n",
    "        ic_end = filter_pwm.shape[0]-1\n",
    "    else:\n",
    "        ic_t = 0.2\n",
    "\n",
    "        # trim PWM of uninformative prefix\n",
    "        ic_start = 0\n",
    "        while ic_start < filter_pwm.shape[0] and info_content(filter_pwm[ic_start:ic_start+1]) < ic_t:\n",
    "            ic_start += 1\n",
    "\n",
    "        # trim PWM of uninformative suffix\n",
    "        ic_end = filter_pwm.shape[0]-1\n",
    "        while ic_end >= 0 and info_content(filter_pwm[ic_end:ic_end+1]) < ic_t:\n",
    "            ic_end -= 1\n",
    "\n",
    "    if ic_start < ic_end:\n",
    "        print('MOTIF filter%d' % f, file=meme_out)\n",
    "        print('letter-probability matrix: alength= 4 w= %d nsites= %d' % (ic_end-ic_start+1, nsites), file=meme_out)\n",
    "\n",
    "        for i in range(ic_start, ic_end+1):\n",
    "            print( '%.4f %.4f %.4f %.4f' % tuple(filter_pwm[i]), file=meme_out)\n",
    "\n",
    "\n",
    "        print( '', file=meme_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2a5d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filter_heat(param_matrix, out_pdf):\n",
    "    param_range = abs(param_matrix).max()\n",
    "\n",
    "    sns.set(font_scale=2)\n",
    "    plt.figure(figsize=(param_matrix.shape[1], 4))\n",
    "    sns.heatmap(param_matrix, cmap='PRGn', linewidths=0.2, vmin=-param_range, vmax=param_range)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels(range(1,param_matrix.shape[1]+1))\n",
    "    ax.set_yticklabels('ACGT', rotation='horizontal') # , size=10)\n",
    "    plt.savefig(out_pdf)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc3e02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_filters(num_filters, tomtom_file, meme_db_file):\n",
    "    ''' Name the filters using Tomtom matches.\n",
    "    Attrs:\n",
    "        num_filters (int) : total number of filters\n",
    "        tomtom_file (str) : filename of Tomtom output table.\n",
    "        meme_db_file (str) : filename of MEME db\n",
    "    Returns:\n",
    "        filter_names [str] :\n",
    "    '''\n",
    "    # name by number\n",
    "    filter_names = ['f%d'%fi for fi in range(num_filters)]\n",
    "\n",
    "    # name by protein\n",
    "    if tomtom_file is not None and meme_db_file is not None:\n",
    "        print(tomtom_file, meme_db_file)\n",
    "        motif_protein = get_motif_proteins(meme_db_file)\n",
    "        # hash motifs and q-value's by filter\n",
    "        filter_motifs = {}\n",
    "\n",
    "        tt_in = open(tomtom_file)\n",
    "        tt_in.readline()\n",
    "        for line in tt_in:\n",
    "            a = line.split()\n",
    "            if a== []:\n",
    "                break\n",
    "            fi = int(a[0][6:])\n",
    "            motif_id = a[1]\n",
    "            qval = float(a[5])\n",
    "\n",
    "            filter_motifs.setdefault(fi,[]).append((qval,motif_id))\n",
    "\n",
    "        tt_in.close()\n",
    "        # assign filter's best match\n",
    "        for fi in filter_motifs:\n",
    "            top_motif = sorted(filter_motifs[fi])[0][1]\n",
    "            filter_names[fi] += '_%s' % motif_protein[top_motif]\n",
    "\n",
    "    return np.array(filter_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9153d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motif_proteins(meme_db_file):\n",
    "    ''' Hash motif_id's to protein names using the MEME DB file '''\n",
    "    motif_protein = {}\n",
    "    for line in open(meme_db_file):\n",
    "        a = line.split()\n",
    "        if len(a) > 0 and a[0] == 'MOTIF':\n",
    "            if a[2][0] == '(':\n",
    "                motif_protein[a[1]] = a[2][1:a[2].find(')')]\n",
    "            else:\n",
    "                motif_protein[a[1]] = a[2]\n",
    "    return motif_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "99689ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filter_bed(filter_num,out_dir):\n",
    "    bed = open(out_dir+'/'+filter_num+'.bed','w')\n",
    "    for key in filter_hits[filter_num].keys():\n",
    "        for peak in filter_hits[filter_num][key]:\n",
    "            print('{0} \\t {1} \\t {2}'.format(key.split('=')[1],peak,peak+motif_length),file=bed) \n",
    "    bed.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "57d47ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motif(filter_weights_old, filter_outs, seqs, out_dir):\n",
    "    global filter_hits\n",
    "    filter_hits = {}\n",
    "    filter_weights = []\n",
    "    for x in filter_weights_old:\n",
    "        x = x - np.mean(x,axis = 0)\n",
    "        filter_weights.append(x)\n",
    "        \n",
    "    filter_weights = np.array(filter_weights)\n",
    "    num_filters = filter_weights.shape[0]\n",
    "    filter_size = filter_weights.shape[2]\n",
    "    filters_ic = []\n",
    "    nsites_list = []\n",
    "    meme_out = meme_intro('%s/filters_meme.txt'%(out_dir), seqs)\n",
    "    for f in range(num_filters):\n",
    "        filter_hits['filter_%i'%f] = {}\n",
    "        # plot filter parameters as a heatmap\n",
    "        plot_filter_heat(filter_weights[f,:,:filter_size], '%s/filter%d_heat.pdf' % (out_dir,f))\n",
    "        # plot weblogo of high scoring outputs\n",
    "        plot_filter_logo(filter_outs[:,f,:], filter_size, seqs, '%s/filter%d_logo'%(out_dir,f), 'filter_%i'%f, maxpct_t=0.8)\n",
    "        generate_filter_bed('filter_%i'%f,out_dir)\n",
    "        # make a PWM for the filter\n",
    "        filter_pwm, nsites = make_filter_pwm('%s/filter%d_logo.fa'%(out_dir,f))\n",
    "        nsites_list.append(nsites)\n",
    "        if nsites < 10:\n",
    "            # no information\n",
    "            filters_ic.append(0)\n",
    "        else:\n",
    "            # compute and save information content\n",
    "            filters_ic.append(info_content(filter_pwm))\n",
    "\n",
    "            # add to the meme motif file\n",
    "            meme_add(meme_out, f, filter_pwm, nsites, False)\n",
    "    pd.DataFrame(filter_hits).to_csv('%s/indices.csv'%out_dir)\n",
    "    meme_out.close()    \n",
    "    subprocess.call('../meme-5.5.2/src/tomtom -dist pearson -thresh 0.05 -oc %s/tomtom %s/filters_meme.txt %s' % (out_dir, out_dir, 'Motif_database/YEASTRACT_20130918.meme'), shell=True)\n",
    "    subprocess.call('cp %s/tomtom/tomtom.tsv %s/tomtom/tomtom.txt' %(out_dir, out_dir), shell=True)\n",
    "    filter_names = name_filters(num_filters, '%s/tomtom/tomtom.txt'%out_dir, 'Motif_database/YEASTRACT_20130918.meme')\n",
    "    \n",
    "    table_out = open('%s/table.txt'%out_dir, 'w')\n",
    "\n",
    "    # print header for later panda reading\n",
    "    table = PrettyTable([\"Filter\", \"consensus\",\"annotation\",\"ic\",\"nsites\"])\n",
    "    header_cols = ('', 'consensus', 'annotation', 'ic', 'mean', 'std')\n",
    "    print('%3s  %19s  %10s  %5s  %6s  %6s' % header_cols, file=table_out)\n",
    "    \n",
    "    for f in range(num_filters):\n",
    "        # collapse to a consensus motif\n",
    "        consensus = filter_motif(filter_weights[f,:,:])\n",
    "\n",
    "        # grab annotation\n",
    "        annotation = '.'\n",
    "        name_pieces = filter_names[f].split('_')\n",
    "        if len(name_pieces) > 1:\n",
    "            annotation = name_pieces[1]\n",
    "        # plot density of filter output scores\n",
    "        fmean, fstd = plot_score_density(np.ravel(filter_outs[: , f , :]), '%s/filter%d_dens.pdf' % (out_dir,f))\n",
    "\n",
    "        row_cols = (f, consensus, annotation, filters_ic[f], fmean, fstd)\n",
    "        table.add_row(list(f, consensus, annotation, filters_ic[f],nsites_list[f]))\n",
    "        print( '%-3d  %19s  %10s  %5.2f  %6.4f  %6.4f' % row_cols, file=table_out)\n",
    "        \n",
    "    table_out.close()\n",
    "    print(table.get_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d01a32e",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8f2119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = data_dir+'/S288C_reference_sequence_R64-3-1_20210421.fsa'\n",
    "peak_file = data_dir+'/Condensin_peaks_quiescence.bed'#data_dir+'/Condensin_peaks_Log.bed'#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "618cb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "global file_extension\n",
    "global device\n",
    "global model_dir\n",
    "global results_dir\n",
    "global data_dir\n",
    "global verbose\n",
    "file_extension = peak_file.split('.')[0].split('_')[-1]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_dir = 'model_'+file_extension\n",
    "results_dir = 'results_'+file_extension\n",
    "data_dir = 'Data'\n",
    "verbose = False\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "if not os.path.exists(results_dir+'/tomtom'):\n",
    "    os.mkdir(results_dir+'/tomtom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c73b4a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2628, 300, 2928, 418)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 500\n",
    "motif_length = 24\n",
    "cross_chrom = True\n",
    "include_dinuc = True\n",
    "calib_data,valid_data,train_data,test_data,peak_sequences_train,peak_sequences_test = extract_data(data_file,peak_file,motif_length,\n",
    "                                                                                                   seq_length,cross_chrom,include_dinuc)\n",
    "len(calib_data),len(valid_data),len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50fc972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_dataset=dataset(calib_data)\n",
    "valid_dataset=dataset(valid_data)\n",
    "train_dataset=dataset(train_data)\n",
    "test_dataset=dataset(test_data)\n",
    "batch_size = 64\n",
    "calib_loader = DataLoader(dataset=calib_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "734a0538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 out of 30\n",
      "no early stopping\n",
      "model 2 out of 30\n",
      "early stopping at epoch  157\n",
      "model 3 out of 30\n",
      "early stopping at epoch  100\n",
      "model 4 out of 30\n",
      "early stopping at epoch  167\n",
      "model 5 out of 30\n",
      "early stopping at epoch  135\n",
      "model 6 out of 30\n",
      "early stopping at epoch  33\n",
      "model 7 out of 30\n",
      "no early stopping\n",
      "model 8 out of 30\n",
      "no early stopping\n",
      "model 9 out of 30\n",
      "no early stopping\n",
      "model 10 out of 30\n",
      "early stopping at epoch  236\n",
      "model 11 out of 30\n",
      "early stopping at epoch  22\n",
      "model 12 out of 30\n",
      "early stopping at epoch  18\n",
      "model 13 out of 30\n",
      "early stopping at epoch  28\n",
      "model 14 out of 30\n",
      "early stopping at epoch  331\n",
      "model 15 out of 30\n",
      "early stopping at epoch  25\n",
      "model 16 out of 30\n",
      "no early stopping\n",
      "model 17 out of 30\n",
      "early stopping at epoch  1\n",
      "model 18 out of 30\n",
      "no early stopping\n",
      "model 19 out of 30\n",
      "early stopping at epoch  24\n",
      "model 20 out of 30\n",
      "early stopping at epoch  27\n",
      "model 21 out of 30\n",
      "early stopping at epoch  167\n",
      "model 22 out of 30\n",
      "early stopping at epoch  390\n",
      "model 23 out of 30\n",
      "early stopping at epoch  32\n",
      "model 24 out of 30\n",
      "early stopping at epoch  28\n",
      "model 25 out of 30\n",
      "early stopping at epoch  33\n",
      "model 26 out of 30\n",
      "no early stopping\n",
      "model 27 out of 30\n",
      "early stopping at epoch  24\n",
      "model 28 out of 30\n",
      "early stopping at epoch  29\n",
      "model 29 out of 30\n",
      "early stopping at epoch  26\n",
      "model 30 out of 30\n",
      "early stopping at epoch  23\n"
     ]
    }
   ],
   "source": [
    "num_motif_list = [30,40,60]\n",
    "num_conv_layers_list = [1,2]\n",
    "dropprob_list = [0, 0.15, 0.3]\n",
    "learning_rate_list = [10**-5,10**-4,10**-3,10**-2]\n",
    "max_num_models = 30\n",
    "maxepochs = 500\n",
    "epochs_for_early_stop = 50\n",
    "best_hyperparameters,results = Calibrate_model(calib_loader,valid_loader, num_motif_list, num_conv_layers_list , dropprob_list,\n",
    "                                               learning_rate_list, max_num_models=max_num_models, maxepochs=maxepochs,\n",
    "                                               epochs_for_early_stop=epochs_for_early_stop,motif_len=motif_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab6eecc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_conv_layers</th>\n",
       "      <th>num_motif</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>331</td>\n",
       "      <td>0.960884</td>\n",
       "      <td>0.965017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>236</td>\n",
       "      <td>0.956518</td>\n",
       "      <td>0.965667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>390</td>\n",
       "      <td>0.950267</td>\n",
       "      <td>0.959962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>26</td>\n",
       "      <td>0.943556</td>\n",
       "      <td>0.952921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>23</td>\n",
       "      <td>0.943326</td>\n",
       "      <td>0.946319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  num_conv_layers num_motif  Dropout  Learning Rate epochs     AUROC     AUPRC\n",
       "0               1        40     0.00         0.0001    331  0.960884  0.965017\n",
       "0               1        60     0.15         0.0001    236  0.956518  0.965667\n",
       "0               1        30     0.30         0.0001    390  0.950267  0.959962\n",
       "0               1        60     0.30         0.0010     26  0.943556  0.952921\n",
       "0               2        30     0.15         0.0010     23  0.943326  0.946319"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "322d7eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_epochs': 331,\n",
       " 'best_num_motif': 40,\n",
       " 'best_num_conv_layers': 1,\n",
       " 'best_dropprob': 0,\n",
       " 'best_l_rate': 0.0001}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "314fee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no early stopping\n",
      "+------------------------+------------+\n",
      "|        Modules         | Parameters |\n",
      "+------------------------+------------+\n",
      "|  conv_layer.0.weight   |    3840    |\n",
      "|   conv_layer.0.bias    |     40     |\n",
      "| project.to_attn_logits |    1600    |\n",
      "|  classifier.0.weight   |    1600    |\n",
      "|   classifier.0.bias    |     40     |\n",
      "|  classifier.3.weight   |     40     |\n",
      "|   classifier.3.bias    |     1      |\n",
      "+------------------------+------------+\n",
      "\n",
      " Total Trainable Params: 7161\n"
     ]
    }
   ],
   "source": [
    "maxepochs = best_hyperparameters['best_epochs']\n",
    "num_motif = best_hyperparameters['best_num_motif']\n",
    "num_conv_layers = best_hyperparameters['best_num_conv_layers']\n",
    "dropprob = best_hyperparameters['best_dropprob']\n",
    "l_rate = best_hyperparameters['best_l_rate']\n",
    "epochs_for_early_stop = 0\n",
    "model = Network(num_motif , motif_length , num_conv_layers , dropprob).to(device)\n",
    "best_model,epochs,train_losses,valid_losses = Train_model(model,train_loader,valid_loader,l_rate ,maxepochs,\n",
    "                                                          epochs_for_early_stop,save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "10ff29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load(model_dir+'/best_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fda8ee23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9750234655800004, 0.9804039156844712)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc,prc = Test_model(best_model,test_loader)\n",
    "auc,prc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca16a8d",
   "metadata": {},
   "source": [
    "# Motif extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "422fe959",
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_sequences=peak_sequences_train.copy()\n",
    "motif_sequences.extend(peak_sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "227ac032",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_Weights = best_model.conv[0].weight.detach().cpu().numpy()\n",
    "filter_bias = best_model.conv[0].bias.detach().cpu().numpy()\n",
    "motif_data=generate_onehot_data(motif_sequences,motif_length=1,label=1,include_dinuc=False)\n",
    "motif_dataset=dataset(motif_data)\n",
    "motif_loader = DataLoader(dataset=motif_dataset,batch_size=batch_size,shuffle=False)\n",
    "out_model = conv_output(filter_Weights,filter_bias,device)\n",
    "filter_output = return_filter_outputs(out_model,motif_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b81cbeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4, 24)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_Weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3342abf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1673, 40, 477)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17059f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output directory 'results_quiescence/tomtom' already exists.\n",
      "Its contents will be overwritten.\n",
      "Processing query 1 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.98277\n",
      "#   Estimated pi_0=0.98277\n",
      "Processing query 2 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00022\n",
      "#   Estimated pi_0=1\n",
      "Processing query 3 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00159\n",
      "#   Estimated pi_0=1\n",
      "Processing query 4 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.987531\n",
      "#   Estimated pi_0=0.992528\n",
      "Processing query 5 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.984326\n",
      "#   Estimated pi_0=0.985457\n",
      "Processing query 6 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00228\n",
      "#   Estimated pi_0=1\n",
      "Processing query 7 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00229\n",
      "#   Estimated pi_0=1\n",
      "Processing query 8 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00228\n",
      "#   Estimated pi_0=1\n",
      "Processing query 9 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00159\n",
      "#   Estimated pi_0=1\n",
      "Processing query 10 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.996787\n",
      "#   Estimated pi_0=0.996787\n",
      "Processing query 11 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.995612\n",
      "#   Estimated pi_0=0.996787\n",
      "Processing query 12 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00067\n",
      "#   Estimated pi_0=1\n",
      "Processing query 13 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00434\n",
      "#   Estimated pi_0=1\n",
      "Processing query 14 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00159\n",
      "#   Estimated pi_0=1\n",
      "Processing query 15 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.993542\n",
      "#   Estimated pi_0=0.994041\n",
      "Processing query 16 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.999019\n",
      "#   Estimated pi_0=1\n",
      "Processing query 17 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.997474\n",
      "#   Estimated pi_0=0.997474\n",
      "Processing query 18 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00297\n",
      "#   Estimated pi_0=1\n",
      "Processing query 19 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.997474\n",
      "#   Estimated pi_0=0.997474\n",
      "Processing query 20 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00022\n",
      "#   Estimated pi_0=1\n",
      "Processing query 21 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00228\n",
      "#   Estimated pi_0=1\n",
      "Processing query 22 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.999498\n",
      "#   Estimated pi_0=1\n",
      "Processing query 23 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00159\n",
      "#   Estimated pi_0=1\n",
      "Processing query 24 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00365\n",
      "#   Estimated pi_0=1\n",
      "Processing query 25 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.994728\n",
      "#   Estimated pi_0=0.994728\n",
      "Processing query 26 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00365\n",
      "#   Estimated pi_0=1\n",
      "Processing query 27 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00022\n",
      "#   Estimated pi_0=1\n",
      "Processing query 28 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00228\n",
      "#   Estimated pi_0=1\n",
      "Processing query 29 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.997682\n",
      "#   Estimated pi_0=0.99816\n",
      "Processing query 30 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00022\n",
      "#   Estimated pi_0=1\n",
      "Processing query 31 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00297\n",
      "#   Estimated pi_0=1\n",
      "Processing query 32 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00091\n",
      "#   Estimated pi_0=1\n",
      "Processing query 33 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.999533\n",
      "#   Estimated pi_0=0.999533\n",
      "Processing query 34 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.999279\n",
      "#   Estimated pi_0=0.999279\n",
      "Processing query 35 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00159\n",
      "#   Estimated pi_0=1\n",
      "Processing query 36 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00365\n",
      "#   Estimated pi_0=1\n",
      "Processing query 37 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00091\n",
      "#   Estimated pi_0=1\n",
      "Processing query 38 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00297\n",
      "#   Estimated pi_0=1\n",
      "Processing query 39 out of 39 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.999752\n",
      "#   Estimated pi_0=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_quiescence/tomtom/tomtom.txt Motif_database/YEASTRACT_20130918.meme\n",
      "+--------+--------------------------+------------+--------------------+------------+------------+\n",
      "| Filter |        consensus         | annotation |         ic         |    mean    |    std     |\n",
      "+--------+--------------------------+------------+--------------------+------------+------------+\n",
      "|   0    | GCGGCGTCACCCTCCGCGGCGGGG |   Rsc30p   | 14.419149256921305 | 0.5028189  | 0.46974477 |\n",
      "|   1    | AGACACGCGAGGCCCGAACTAAGC |     .      | 12.313179315396603 | 0.5533662  | 0.4650118  |\n",
      "|   2    | GGAAGGGAAGGGAAAGGAGCATGT |     .      | 17.370143735017816 | 0.15898034 | 0.29140145 |\n",
      "|   3    | GTCGCGCTTGCCGCGGCGGGTGGG |     .      | 9.317983973285367  | 0.41138998 | 0.46446398 |\n",
      "|   4    | GCTTCGTCCGCGCCTCGGCCGGCG |     .      |  9.33817001108833  | 0.5266196  | 0.45093322 |\n",
      "|   5    | TATCTGTTTTTCTTTTGACTTTTC |     .      | 28.620178395528733 | 0.4492615  | 0.50743675 |\n",
      "|   6    | AACTTGCGGTTCCCCGGGTTAAAT |     .      | 10.005553017307317 | 0.6749601  | 0.5235164  |\n",
      "|   7    | AAAAAAAAAACATACCCCTAAAAA |     .      | 25.844595932831105 | 0.20795704 | 0.32856426 |\n",
      "|   8    | ACGTGCGGTCAAATTAAACTGACG |     .      | 10.457593169194597 | 0.4926564  |  0.509187  |\n",
      "|   9    | TAAAGCGAACGAGGTCTTTAATTC |   Kar4p    | 12.472801125282032 | 0.80416244 | 0.5537492  |\n",
      "|   10   | TTAATGCACTTAAGTTATTAGTTA |     .      | 14.220977499543304 | 0.93795896 | 0.5314049  |\n",
      "|   11   | CAAATCCACCTGTGATTAGTTTAC |     .      |         0          | 0.7738405  | 0.48652154 |\n",
      "|   12   | CTCTTGCGTGCTCCGCGGGGTTCT |     .      | 11.370754322324235 | 0.33317655 | 0.38905847 |\n",
      "|   13   | TAAAACGTAGGCGTCCTTGAGACT |     .      | 9.565794017644317  | 0.7657401  | 0.48184192 |\n",
      "|   14   | TTGGCGCGAGGCTTGGTACTTTCC |     .      | 9.048133451877856  | 0.83133066 | 0.61329293 |\n",
      "|   15   | TACATACAACTATGCAAATTTATC |   Nhp6ap   | 19.19640929711226  | 1.2679392  | 0.7282684  |\n",
      "|   16   | CGTTTACTCGGTTAGACTTATTCA |     .      | 12.594656911215765 | 0.6877916  | 0.48214287 |\n",
      "|   17   | CTTACCTTTTTATATATATATACG |     .      | 27.835860277227667 | 0.45769256 | 0.4487869  |\n",
      "|   18   | GGGTCAAAATCCTACCTGGCAGTG |     .      | 9.911709778084065  | 0.4963107  | 0.44276294 |\n",
      "|   19   | GTGAGAAGAGGAAGATGGGAGAAT |     .      | 17.170562441656845 | 0.1718057  | 0.2967943  |\n",
      "|   20   | GGAAAGGCAAAAGCAGCACAAGGG |     .      | 11.602889590222041 | 0.29643133 | 0.38657635 |\n",
      "|   21   | CTTTTTCTTTTTCTTTCATTTTTA |     .      | 28.221856166790555 | 0.35778555 | 0.34899342 |\n",
      "|   22   | TCGGGTCGGCCTAAGGATCAAGGG |     .      |  9.31897823586955  | 0.7493576  | 0.62824696 |\n",
      "|   23   | CTCCCGCTTTTTTTCTTTCTTTCC |     .      | 22.88773843097589  | 0.2956151  | 0.44252205 |\n",
      "|   24   | ATGTTGCTCGTCGCTCGGAGTTCC |     .      | 9.130008907415533  | 0.91576517 | 0.48208836 |\n",
      "|   25   | TTTTAAAAAAAAATTTATTTTAAT |   Sum1p    | 23.20590468553672  | 0.1895958  | 0.3497954  |\n",
      "|   26   | GGCTAGGAGCCCGAAGGAGTAGGG |     .      | 11.517737844005419 | 0.7386246  | 0.5129861  |\n",
      "|   27   | GCAGCATAAAAGGATCCGGAACTG |     .      | 9.794327926207714  | 1.0683389  | 0.5658197  |\n",
      "|   28   | ATAAAGGAAAAAATACAACAATAT |     .      | 26.231553530531258 | 0.24067962 | 0.35556352 |\n",
      "|   29   | AGAAAAACCGAGCCGCCCGAGATA |     .      | 10.177814469283708 | 1.0143143  | 0.6029145  |\n",
      "|   30   | TGAAGGGAAAATAGTTATAAAAAG |   Hsf1p    | 18.703502323816092 | 0.23533541 | 0.33590847 |\n",
      "|   31   | TCAAACGGAAAGTCGAGTCGCAAC |   Azf1p    | 11.113410830393445 | 0.8101981  | 0.56118673 |\n",
      "|   32   | GGAAAGAAAGGGGGAGAGGGAGTG |     .      | 19.022023778752914 | 0.11073202 | 0.23579678 |\n",
      "|   33   | CTGATCCATTGGATCTATCTTTAC |     .      | 12.285462353388272 | 0.7242275  | 0.46227652 |\n",
      "|   34   | GCAGTCGCGCCGGCTGAAAGAGCG |     .      | 10.769498842787936 | 1.5638862  | 0.8231781  |\n",
      "|   35   | CCTTGGGATTGGCTTTAATTTAAT |     .      | 11.53257431143521  | 0.47922957 | 0.4898305  |\n",
      "|   36   | CTGACTTTTGGCTCGGTCCGGCCC |     .      | 9.293248204085328  | 0.5320357  | 0.4758479  |\n",
      "|   37   | TCAAATAAAAGGGAAGCCCCAACT |     .      | 11.552332528121529 | 0.98857594 | 0.55493176 |\n",
      "|   38   | CGTTTTTAGTGGTTCGTGATCTCC |     .      | 13.072411577436865 | 0.92989063 | 0.55881673 |\n",
      "|   39   | GGAGATAAATCGGACCCAGCCAAA |     .      | 10.966283376904531 | 0.63643515 | 0.53676283 |\n",
      "+--------+--------------------------+------------+--------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "get_motif(filter_Weights,filter_output,motif_sequences,results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eaf43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
