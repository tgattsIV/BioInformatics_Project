{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea054c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math \n",
    "import random\n",
    "import gzip\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from torch import einsum\n",
    "import seaborn as sns\n",
    "import subprocess\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc92a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weblogo_opts = '-X NO -Y NO --errorbars NO --fineprint \"\"'\n",
    "weblogo_opts = '-X NO --fineprint \"\"'\n",
    "weblogo_opts += ' -C \"#CB2026\" A A'\n",
    "weblogo_opts += ' -C \"#34459C\" C C'\n",
    "weblogo_opts += ' -C \"#FBB116\" G G'\n",
    "# embed\n",
    "weblogo_opts += ' -C \"#0C8040\" T T'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e64639",
   "metadata": {},
   "source": [
    "# DATA Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ff4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chrom_train_test(peaks,Chr_dict):\n",
    "    peak_chromosomes = {}\n",
    "    n_peaks = 0\n",
    "    chrom_train = []\n",
    "    chrom_test = []\n",
    "    for line in peaks:\n",
    "        split_line = 'chromosome='+line.split('\\t')[0]\n",
    "        peak_chromosomes[split_line] = peak_chromosomes.get(split_line,0) + 1\n",
    "        n_peaks+=1\n",
    "    size_test = int(n_peaks/10)\n",
    "    npeaks_test = 0\n",
    "    while npeaks_test<size_test:\n",
    "        chrom = random.choice(list(Chr_dict.keys()))\n",
    "        npeaks_test += peak_chromosomes[chrom]\n",
    "        chrom_test.append(chrom)\n",
    "        if npeaks_test>int(n_peaks*1.3/10):\n",
    "            npeaks_test = 0\n",
    "            chrom_test = []\n",
    "    for chrom in Chr_dict.keys():\n",
    "        if chrom not in chrom_test:\n",
    "            chrom_train.append(chrom)\n",
    "    return chrom_train,chrom_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4831bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genome_data(data_file):\n",
    "    data=open(data_file).read()\n",
    "    chromosomes_data = data.split('>')[1:]\n",
    "    return (chromosomes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a84bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_bed_file(chromosomes_data,peak_file,seq_length,Chr_dict,cross_chrom):\n",
    "    peaks = open(peak_file).readlines()\n",
    "    peak_sequences = []\n",
    "    if cross_chrom:\n",
    "        peak_sequences_train,peak_sequences_test = [],[]\n",
    "        chrom_train , chrom_test = generate_chrom_train_test(peaks,Chr_dict)\n",
    "    for peak in peaks:\n",
    "        peak_split = peak.split('\\t')\n",
    "        Chr = 'chromosome='+str(peak_split[0])\n",
    "        if Chr in Chr_dict:\n",
    "            chrom_seq = Chr_dict[Chr]\n",
    "            n = len(chrom_seq)\n",
    "            start_idx = max(int(peak_split[1])-seq_length//2,0)\n",
    "            end_idx = min(int(len(chrom_seq)), start_idx+seq_length)\n",
    "            if end_idx == len(chrom_seq):\n",
    "                start_idx = end_idx - seq_length\n",
    "            header = Chr+':{0}-{1}'.format(start_idx,end_idx)\n",
    "            if not cross_chrom:\n",
    "                peak_sequences.append([header,chrom_seq[start_idx:end_idx]])\n",
    "            else:\n",
    "                if Chr in chrom_train:\n",
    "                    peak_sequences_train.append([header,chrom_seq[start_idx:end_idx]])\n",
    "                else:\n",
    "                    peak_sequences_test.append([header,chrom_seq[start_idx:end_idx]])\n",
    "    if not cross_chrom:\n",
    "        size=int(len(peak_sequences)/10)\n",
    "        peak_sequences_train = peak_sequences[:9*size]\n",
    "        peak_sequences_test = peak_sequences[9*size:]\n",
    "    return (peak_sequences_train,peak_sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d07964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dinucshuffle(sequence):\n",
    "    b=[sequence[i:i+2] for i in range(0, len(sequence), 2)]\n",
    "    random.shuffle(b)\n",
    "    d=''.join([str(x) for x in b])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584b788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqtopad(sequence, motif_len):\n",
    "    rows=len(sequence)+2*motif_len-2\n",
    "    S=np.empty([rows,4])\n",
    "    base=['A', 'C', 'G', 'T']\n",
    "    for i in range(rows):\n",
    "        for j in range(4):\n",
    "            if (i-motif_len+1<len(sequence) and sequence[i-motif_len+1]=='N' \n",
    "                or i<motif_len-1 or i>len(sequence)+motif_len-2):\n",
    "                S[i,j]=np.float32(0.25)\n",
    "            elif sequence[i-motif_len+1]==base[j]:\n",
    "                S[i,j]=np.float32(1)\n",
    "            else:\n",
    "                S[i,j]=np.float32(0)\n",
    "    return np.transpose(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0f38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_onehot_data(peak_sequences,motif_length,label,include_dinuc):\n",
    "    alldata = []\n",
    "    for header,seq in peak_sequences:\n",
    "        alldata.append([header,seq,seqtopad(seq,motif_length),[int(label)]])#\n",
    "        if include_dinuc:\n",
    "            shuff_seq = dinucshuffle(seq)\n",
    "            alldata.append([header,shuff_seq,seqtopad(shuff_seq,motif_length),[0]])#\n",
    "    return (alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d582c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(data_file,peak_file,motif_length=24,seq_length=150,cross_chrom=False,include_dinuc=True,Chr_dict=None):\n",
    "    chromosomes_data = genome_data(data_file)\n",
    "    if Chr_dict==None:\n",
    "        Chr_dict = {}\n",
    "        for chrom_data in chromosomes_data:\n",
    "            ref = chrom_data.split('\\n')[0].split(' ')[-1][1:-1]\n",
    "            Chr_dict[ref]=''.join(chrom_data.split('\\n')[1:])\n",
    "        Chr_dict['chromosome=Mito'] = Chr_dict.pop('top=circular')\n",
    "    if type(peak_file) == str:\n",
    "        peak_sequences_train,peak_sequences_test = Read_bed_file(chromosomes_data,peak_file,seq_length,Chr_dict,cross_chrom)\n",
    "        train_data = generate_onehot_data(peak_sequences_train,motif_length,1,include_dinuc)\n",
    "        test_data = generate_onehot_data(peak_sequences_test,motif_length,1,include_dinuc)\n",
    "        random.shuffle(train_data)\n",
    "        size=int(len(train_data)/10)\n",
    "        calib_data=train_data[:9*size]\n",
    "        valid_data=train_data[9*size:]\n",
    "    elif type(peak_file) == list:\n",
    "        include_dinuc = False\n",
    "        peak_sequences_train,peak_sequences_test = [],[]\n",
    "        train_data,test_data = [],[]\n",
    "        for i in range (len(peak_file)):\n",
    "            peak_sequences_train_temp,peak_sequences_test_temp = Read_bed_file(chromosomes_data,peak_file[i],seq_length,Chr_dict,cross_chrom)\n",
    "            peak_sequences_train.extend(peak_sequences_train_temp)\n",
    "            peak_sequences_test.extend(peak_sequences_test_temp)\n",
    "            train_data.extend(generate_onehot_data(peak_sequences_train_temp,motif_length,i,include_dinuc))\n",
    "            test_data.extend(generate_onehot_data(peak_sequences_test_temp,motif_length,i,include_dinuc))\n",
    "        random.shuffle(train_data)\n",
    "        random.shuffle(test_data)\n",
    "        size=int(len(train_data)/10)\n",
    "        calib_data=train_data[:9*size]\n",
    "        valid_data=train_data[9*size:]\n",
    "    return calib_data,valid_data,train_data,test_data,peak_sequences_train,peak_sequences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c6057d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, xy=None):\n",
    "        self.header=[el[0] for el in xy]\n",
    "        self.seq =[el[1] for el in xy ]\n",
    "        self.x_data=np.asarray([el[2] for el in xy],dtype=np.float32)\n",
    "        self.y_data =np.asarray([el[3] for el in xy ],dtype=np.float32)\n",
    "        self.x_data = torch.from_numpy(self.x_data)\n",
    "        self.y_data = torch.from_numpy(self.y_data)\n",
    "        self.length=len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.header[index],self.seq[index],self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef79b14",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70a7e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPool(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.to_attn_logits = nn.Parameter(torch.eye(dim)) \n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_logits = einsum('b n d, d e -> b n e', x, self.to_attn_logits) \n",
    "        attn = attn_logits.softmax(dim = -2) \n",
    "        return (x * attn).sum(dim = -2).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e31aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, num_motif , motif_len , num_conv_layers , dropprob):\n",
    "        super(Network, self).__init__()\n",
    "        self.num_motif = num_motif\n",
    "        self.conv = [nn.Conv1d(4, num_motif, kernel_size=motif_len),nn.ReLU(inplace=True)]\n",
    "        in_channels = num_motif\n",
    "        for i in range (num_conv_layers-1):\n",
    "            motif_len = motif_len//2\n",
    "            self.conv.append(nn.MaxPool1d(kernel_size=3))\n",
    "            self.conv.append(nn.Conv1d(in_channels, int(1.5*in_channels), kernel_size=motif_len))\n",
    "            self.conv.append(nn.ReLU(inplace=True))\n",
    "            in_channels = int(1.5*in_channels)\n",
    "        self.conv_layer = nn.Sequential(*self.conv)\n",
    "        self.project = AttentionPool(in_channels)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_channels , in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropprob, inplace=False),\n",
    "            nn.Linear(in_channels, 1),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x= x.permute(0, 2, 1)\n",
    "        x = self.project(x)\n",
    "        predict = self.classifier(x)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fb2ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_output(nn.Module):\n",
    "    def __init__(self,filter_weights,filter_bias,device):\n",
    "        super(conv_output, self).__init__()\n",
    "        if type(filter_weights) is np.ndarray:\n",
    "            self.filter_weights =  torch.from_numpy(filter_weights.astype(np.float32)).to(device)\n",
    "        else :\n",
    "            self.filter_weights = filter_weights.to(device)\n",
    "        if type(filter_bias) is np.ndarray:\n",
    "            self.filter_bias =  torch.from_numpy(filter_bias.astype(np.float32)).to(device)\n",
    "        else :\n",
    "            self.filter_bias = filter_bias.to(device)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.conv1d(x, self.filter_weights, bias=self.filter_bias, stride=1, padding=0)\n",
    "        out=x.clamp(min=0)\n",
    "        return (out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0649a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### printing parameters ------------------\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table.get_string())\n",
    "    print(f\"\\n Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d6ce6",
   "metadata": {},
   "source": [
    "# Calib - Train - Test functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79573514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_model(model,train_loader,valid_loader, l_rate=0.01 , maxepochs=100,epochs_for_early_stop=0,save_model=False):\n",
    "    best_model = None\n",
    "    best_loss = np.inf\n",
    "    counter = 0\n",
    "    nepochs=0\n",
    "    valid_losses =[]\n",
    "    train_losses = []\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=l_rate,weight_decay=1e-05)\n",
    "    criterion = nn.BCELoss(reduction='mean')\n",
    "    while nepochs<maxepochs:\n",
    "        model.train()\n",
    "        train_loss=0\n",
    "        for i, (header, seq, data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)#\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()\n",
    "        if verbose:\n",
    "            print('Model trained for {0} epochs out of {2}. Training loss is {1}'.format(nepochs+1,loss.item(),maxepochs))\n",
    "        train_losses.append(train_loss/(i+1))\n",
    "        with torch.no_grad():\n",
    "            model.eval() \n",
    "            valid_loss=0\n",
    "            for i, (header, seq, data, target) in enumerate(valid_loader):\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = F.binary_cross_entropy(output, target)#\n",
    "                valid_loss+=loss.item()\n",
    "            valid_losses.append(valid_loss/(i+1))\n",
    "        counter+=1\n",
    "        nepochs +=1\n",
    "        if epochs_for_early_stop>0:\n",
    "            if valid_losses[-1]<best_loss:\n",
    "                if verbose:\n",
    "                    print('Validation loss decreased from {0} to {1}'.format(best_loss,valid_losses[-1]))\n",
    "                best_loss = valid_losses[-1]\n",
    "                best_model = model\n",
    "                counter = 0\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('Counter for early stopping: {0} out of {1}'.format(counter,epochs_for_early_stop))\n",
    "                if counter == epochs_for_early_stop:\n",
    "                    print('early stopping at epoch ', nepochs-counter)\n",
    "                    if save_model:\n",
    "                        torch.save(best_model,model_dir+'/best_model.pkl')\n",
    "                        count_parameters(best_model)\n",
    "                    return (best_model,nepochs-counter,train_losses,valid_losses)\n",
    "    print('no early stopping')\n",
    "    if save_model:\n",
    "        torch.save(model,model_dir+'/best_model.pkl')\n",
    "        count_parameters(model)\n",
    "    return (model,nepochs,train_losses,valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88e481f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_model(model,test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        pred_list = []\n",
    "        labels_list = []\n",
    "        for i, (header, seq, data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
    "            labels=target.cpu().numpy().reshape(output.shape[0])\n",
    "            pred_list.append(pred)\n",
    "            labels_list.append(labels)\n",
    "        labels = np.concatenate(labels_list)\n",
    "        predictions = np.concatenate(pred_list)\n",
    "    auc = metrics.roc_auc_score(labels, predictions)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(labels, predictions)\n",
    "    prc = (metrics.auc(recall, precision))\n",
    "    if verbose:\n",
    "        print('AUROC on test data ', auc)\n",
    "        print('AUPRC on test data ', prc)\n",
    "    return (auc,prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e24718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calibrate_model(calib_loader,valid_loader, num_motif_list, num_conv_layers_list , dropprob_list,learning_rate_list, \n",
    "                    max_num_models=40, maxepochs=100,epochs_for_early_stop=0 , motif_len=24 ):\n",
    "    results=pd.DataFrame(columns=['num_conv_layers','num_motif','Dropout','Learning Rate','epochs','AUROC','AUPRC'])\n",
    "    best_AUC = 0\n",
    "    if verbose:\n",
    "        print('Training on ',device)\n",
    "    for number in range(max_num_models):\n",
    "        print('model {0} out of {1}'.format(number+1,max_num_models))\n",
    "        # hyper-parameters\n",
    "        num_motif = random.choice(num_motif_list)\n",
    "        num_conv_layers = random.choice(num_conv_layers_list)\n",
    "        dropprob = random.choice(dropprob_list)\n",
    "        l_rate = random.choice(learning_rate_list)\n",
    "        while ((results['num_conv_layers']==num_conv_layers) & (results['num_motif']==num_motif) \n",
    "               & (results['Dropout']==dropprob) & (results['Learning Rate']==l_rate)).any(): \n",
    "            #if hyperparameters exist in the results dataframe then randomly choose other parameters\n",
    "            num_motif = random.choice(num_motif_list)\n",
    "            num_conv_layers = random.choice(num_conv_layers_list)\n",
    "            dropprob = random.choice(dropprob_list)\n",
    "            l_rate = random.choice(learning_rate_list)\n",
    "        model = Network(num_motif , motif_len , num_conv_layers , dropprob).to(device)#num_conv_layers,dropprob\n",
    "        best_model,epochs,train_losses,valid_losses = Train_model(model,calib_loader,valid_loader,l_rate ,maxepochs,epochs_for_early_stop)\n",
    "        auc,prc = Test_model(best_model,valid_loader)\n",
    "        results=pd.concat([results,pd.DataFrame({'num_conv_layers':num_conv_layers,'num_motif':num_motif,'Dropout':dropprob,\n",
    "                                                 'Learning Rate':l_rate,'epochs':epochs,'AUROC':[auc],'AUPRC':[prc]})])\n",
    "        if auc > best_AUC :\n",
    "            best_AUC = auc\n",
    "            best_epochs = epochs\n",
    "            best_num_motif = num_motif\n",
    "            best_num_conv_layers = num_conv_layers\n",
    "            best_dropprob = dropprob\n",
    "            best_l_rate = l_rate\n",
    "    best_hyperparameters = {'best_epochs': best_epochs,'best_num_motif':best_num_motif,\n",
    "                            'best_num_conv_layers':best_num_conv_layers,'best_dropprob':best_dropprob,'best_l_rate':best_l_rate}\n",
    "    torch.save(best_hyperparameters, model_dir+'/best_hyperpamarameters.pth')\n",
    "    results.sort_values(by='AUROC',ascending=False,inplace=True)\n",
    "    results.to_csv(model_dir+'/calibration_df.csv',index=False)\n",
    "    return best_hyperparameters,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c32a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_filter_outputs(model,test_loader):\n",
    "    with torch.no_grad():\n",
    "        best_model.eval()\n",
    "        pred_list = []\n",
    "        for i, (header, seq, data, target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred=output.cpu().detach().numpy()\n",
    "            pred_list.append(pred)\n",
    "        predictions = np.concatenate(pred_list)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532222b",
   "metadata": {},
   "source": [
    "# Motif extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ebd21d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_content(pwm, transpose=False, bg_gc=0.415):\n",
    "    ''' Compute PWM information content.\n",
    "    In the original analysis, I used a bg_gc=0.5. For any\n",
    "    future analysis, I ought to switch to the true hg19\n",
    "    value of 0.415.\n",
    "    '''\n",
    "    pseudoc = 1e-9\n",
    "    if transpose:\n",
    "        pwm = np.transpose(pwm)\n",
    "\n",
    "    bg_pwm = [1-bg_gc, bg_gc, bg_gc, 1-bg_gc]\n",
    "\n",
    "    ic = 0\n",
    "    for i in range(pwm.shape[0]):\n",
    "        for j in range(4):\n",
    "            # ic += 0.5 + pwm[i][j]*np.log2(pseudoc+pwm[i][j])\n",
    "            ic += -bg_pwm[j]*np.log2(bg_pwm[j]) + pwm[i][j]*np.log2(pseudoc+pwm[i][j])\n",
    "    return ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76c17aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meme_intro(meme_file, seqs):\n",
    "    ''' Open MEME motif format file and print intro\n",
    "    Attrs:\n",
    "        meme_file (str) : filename\n",
    "        seqs [str] : list of strings for obtaining background freqs\n",
    "    Returns:\n",
    "        mem_out : open MEME file\n",
    "    '''\n",
    "    nts = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "\n",
    "    # count\n",
    "    nt_counts = [1]*4\n",
    "    for i in range(len(seqs)):\n",
    "        for nt in seqs[i][1]:\n",
    "            try:\n",
    "                nt_counts[nts[nt]] += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    # normalize\n",
    "    nt_sum = float(sum(nt_counts))\n",
    "    nt_freqs = [nt_counts[i]/nt_sum for i in range(4)]\n",
    "\n",
    "    # open file for writing\n",
    "    meme_out = open(meme_file, 'w')\n",
    "\n",
    "    # print intro material\n",
    "    print( 'MEME version 4', file=meme_out)\n",
    "    print( '', file=meme_out)\n",
    "    #embd\n",
    "\n",
    "    print( 'ALPHABET= ACGT', file=meme_out)        \n",
    "    \n",
    "    print( '', file=meme_out)\n",
    "    print( 'Background letter frequencies:', file=meme_out)\n",
    "    #embd\n",
    "    print( 'A %.4f C %.4f G %.4f T %.4f' % tuple(nt_freqs), file=meme_out)\n",
    "    print( '', file=meme_out)\n",
    "    return meme_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d58a1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filter_pwm(filter_fasta):\n",
    "    ''' Make a PWM for this filter from its top hits '''\n",
    "    nts = {'A':0, 'C':1, 'G':2, 'T':3}\n",
    "    #embd\n",
    "    pwm_counts = []\n",
    "    nsites = 4 # pseudocounts\n",
    "    for line in open(filter_fasta):\n",
    "        if line[0] != '>':\n",
    "            seq = line.rstrip()\n",
    "            nsites += 1\n",
    "            if len(pwm_counts) == 0:\n",
    "                # initialize with the length\n",
    "                for i in range(len(seq)):\n",
    "                    pwm_counts.append(np.array([1.0]*4))\n",
    "\n",
    "            # count\n",
    "            for i in range(len(seq)):\n",
    "                try:\n",
    "                    pwm_counts[i][nts[seq[i]]] += 1\n",
    "                except KeyError:\n",
    "                    pwm_counts[i] += np.array([0.25]*4)\n",
    "\n",
    "    # normalize\n",
    "    pwm_freqs = []\n",
    "    for i in range(len(pwm_counts)):\n",
    "        pwm_freqs.append([pwm_counts[i][j]/float(nsites) for j in range(4)])\n",
    "\n",
    "    return np.array(pwm_freqs), nsites-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58673d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_density(f_scores, out_pdf):\n",
    "    sns.set(font_scale=1.3)\n",
    "    plt.figure()\n",
    "    sns.distplot(f_scores, kde=False)\n",
    "    plt.xlabel('ReLU output')\n",
    "    plt.savefig(out_pdf)\n",
    "    plt.close()\n",
    "\n",
    "    return f_scores.mean(), f_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "948f58b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_motif(param_matrix):\n",
    "    nts = 'ACGT'\n",
    "    motif_list = []\n",
    "    for v in range(param_matrix.shape[1]):\n",
    "        max_n = 0\n",
    "        for n in range(1,4):\n",
    "            if param_matrix[n,v] > param_matrix[max_n,v]:\n",
    "                max_n = n\n",
    "\n",
    "        if param_matrix[max_n,v] > 0:\n",
    "            motif_list.append(nts[max_n])\n",
    "        else:\n",
    "            motif_list.append('N')\n",
    "\n",
    "    return ''.join(motif_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc48f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filter_heat(param_matrix, out_pdf):\n",
    "    param_range = abs(param_matrix).max()\n",
    "\n",
    "    sns.set(font_scale=2)\n",
    "    plt.figure(figsize=(param_matrix.shape[1], 4))\n",
    "    sns.heatmap(param_matrix, cmap='PRGn', linewidths=0.2, vmin=-param_range, vmax=param_range)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels(range(1,param_matrix.shape[1]+1))\n",
    "    ax.set_yticklabels('ACGT', rotation='horizontal') # , size=10)\n",
    "    plt.savefig(out_pdf)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cebfb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filter_logo(filter_outs, filter_size, seqs, out_prefix, raw_t=0, maxpct_t=None):\n",
    "    if maxpct_t:\n",
    "        all_outs = np.ravel(filter_outs)\n",
    "        all_outs_mean = all_outs.mean()\n",
    "        all_outs_norm = all_outs - all_outs_mean\n",
    "        raw_t = 0.65 * all_outs_norm.max() + all_outs_mean\n",
    "        #raw_t = 0.65 * all_outs_norm.max() + all_outs_mean\n",
    "    # print fasta file of positive outputs\n",
    "    filter_fasta_out = open('%s.fa' % out_prefix, 'w')\n",
    "    filter_count = 0\n",
    "    for i in range(filter_outs.shape[0]):\n",
    "        for j in range(filter_outs.shape[1]):\n",
    "            if filter_outs[i,j] > raw_t:\n",
    "                #print(len(seqs[i]))\n",
    "                fw.write(str(j))\n",
    "                fw.write('\\n')\n",
    "                kmer = seqs[i][1][j:j+filter_size]\n",
    "                #kmer = kmer.replace('T','U')\n",
    "                incl_kmer = len(kmer) - kmer.count('N')\n",
    "                if incl_kmer <filter_size:\n",
    "                    continue\n",
    "                print('>%d_%d' % (i,j), file=filter_fasta_out)\n",
    "                print(kmer, file=filter_fasta_out)\n",
    "                filter_count += 1\n",
    "    filter_fasta_out.close()\n",
    "    \n",
    "    # make weblogo\n",
    "    if filter_count > 0:\n",
    "        weblogo_cmd = 'weblogo %s < %s.fa > %s.eps' % (weblogo_opts, out_prefix, out_prefix)\n",
    "        subprocess.call(weblogo_cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5465afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meme_add(meme_out, f, filter_pwm, nsites, trim_filters=False):\n",
    "    ''' Print a filter to the growing MEME file\n",
    "    Attrs:\n",
    "        meme_out : open file\n",
    "        f (int) : filter index #\n",
    "        filter_pwm (array) : filter PWM array\n",
    "        nsites (int) : number of filter sites\n",
    "    '''\n",
    "    if not trim_filters:\n",
    "        ic_start = 0\n",
    "        ic_end = filter_pwm.shape[0]-1\n",
    "    else:\n",
    "        ic_t = 0.2\n",
    "\n",
    "        # trim PWM of uninformative prefix\n",
    "        ic_start = 0\n",
    "        while ic_start < filter_pwm.shape[0] and info_content(filter_pwm[ic_start:ic_start+1]) < ic_t:\n",
    "            ic_start += 1\n",
    "\n",
    "        # trim PWM of uninformative suffix\n",
    "        ic_end = filter_pwm.shape[0]-1\n",
    "        while ic_end >= 0 and info_content(filter_pwm[ic_end:ic_end+1]) < ic_t:\n",
    "            ic_end -= 1\n",
    "\n",
    "    if ic_start < ic_end:\n",
    "        print('MOTIF filter%d' % f, file=meme_out)\n",
    "        print('letter-probability matrix: alength= 4 w= %d nsites= %d' % (ic_end-ic_start+1, nsites), file=meme_out)\n",
    "\n",
    "        for i in range(ic_start, ic_end+1):\n",
    "            print( '%.4f %.4f %.4f %.4f' % tuple(filter_pwm[i]), file=meme_out)\n",
    "\n",
    "\n",
    "        print( '', file=meme_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2a5d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filter_heat(param_matrix, out_pdf):\n",
    "    param_range = abs(param_matrix).max()\n",
    "\n",
    "    sns.set(font_scale=2)\n",
    "    plt.figure(figsize=(param_matrix.shape[1], 4))\n",
    "    sns.heatmap(param_matrix, cmap='PRGn', linewidths=0.2, vmin=-param_range, vmax=param_range)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels(range(1,param_matrix.shape[1]+1))\n",
    "    ax.set_yticklabels('ACGT', rotation='horizontal') # , size=10)\n",
    "    plt.savefig(out_pdf)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cc3e02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_filters(num_filters, tomtom_file, meme_db_file):\n",
    "    ''' Name the filters using Tomtom matches.\n",
    "    Attrs:\n",
    "        num_filters (int) : total number of filters\n",
    "        tomtom_file (str) : filename of Tomtom output table.\n",
    "        meme_db_file (str) : filename of MEME db\n",
    "    Returns:\n",
    "        filter_names [str] :\n",
    "    '''\n",
    "    # name by number\n",
    "    filter_names = ['f%d'%fi for fi in range(num_filters)]\n",
    "\n",
    "    # name by protein\n",
    "    if tomtom_file is not None and meme_db_file is not None:\n",
    "        print(tomtom_file, meme_db_file)\n",
    "        motif_protein = get_motif_proteins(meme_db_file)\n",
    "        # hash motifs and q-value's by filter\n",
    "        filter_motifs = {}\n",
    "\n",
    "        tt_in = open(tomtom_file)\n",
    "        tt_in.readline()\n",
    "        for line in tt_in:\n",
    "            a = line.split()\n",
    "            if a== []:\n",
    "                break\n",
    "            fi = int(a[0][6:])\n",
    "            motif_id = a[1]\n",
    "            qval = float(a[5])\n",
    "\n",
    "            filter_motifs.setdefault(fi,[]).append((qval,motif_id))\n",
    "\n",
    "        tt_in.close()\n",
    "        # assign filter's best match\n",
    "        for fi in filter_motifs:\n",
    "            top_motif = sorted(filter_motifs[fi])[0][1]\n",
    "            filter_names[fi] += '_%s' % motif_protein[top_motif]\n",
    "\n",
    "    return np.array(filter_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9153d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motif_proteins(meme_db_file):\n",
    "    ''' Hash motif_id's to protein names using the MEME DB file '''\n",
    "    motif_protein = {}\n",
    "    for line in open(meme_db_file):\n",
    "        a = line.split()\n",
    "        if len(a) > 0 and a[0] == 'MOTIF':\n",
    "            if a[2][0] == '(':\n",
    "                motif_protein[a[1]] = a[2][1:a[2].find(')')]\n",
    "            else:\n",
    "                motif_protein[a[1]] = a[2]\n",
    "    return motif_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57d47ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motif(filter_weights_old, filter_outs, seqs, out_dir):\n",
    "    global fw\n",
    "    filter_weights = []\n",
    "    for x in filter_weights_old:\n",
    "        x = x - np.mean(x,axis = 0)\n",
    "        filter_weights.append(x)\n",
    "        \n",
    "    filter_weights = np.array(filter_weights)\n",
    "    num_filters = filter_weights.shape[0]\n",
    "    filter_size = filter_weights.shape[2]\n",
    "    filters_ic = []\n",
    "    meme_out = meme_intro('%s/filters_meme.txt'%(out_dir), seqs)\n",
    "    fw = open('indices.txt', 'w')\n",
    "    for f in range(num_filters):\n",
    "        # plot filter parameters as a heatmap\n",
    "        plot_filter_heat(filter_weights[f,:,:filter_size], '%s/filter%d_heat.pdf' % (out_dir,f))\n",
    "\n",
    "        # plot weblogo of high scoring outputs\n",
    "        plot_filter_logo(filter_outs[:,f,:], filter_size, seqs, '%s/filter%d_logo'%(out_dir,f), maxpct_t=0.5)\n",
    "\n",
    "        # make a PWM for the filter\n",
    "        filter_pwm, nsites = make_filter_pwm('%s/filter%d_logo.fa'%(out_dir,f))\n",
    "\n",
    "        if nsites < 10:\n",
    "            # no information\n",
    "            filters_ic.append(0)\n",
    "        else:\n",
    "            # compute and save information content\n",
    "            filters_ic.append(info_content(filter_pwm))\n",
    "\n",
    "            # add to the meme motif file\n",
    "            meme_add(meme_out, f, filter_pwm, nsites, False)\n",
    "\n",
    "    meme_out.close()\n",
    "    fw.close()\n",
    "    \n",
    "    subprocess.call('/s/chopin/k/grad/adaoud/meme-5.5.2/src/tomtom -dist pearson -thresh 0.05 -oc %s/tomtom %s/filters_meme.txt %s' % (out_dir, out_dir, 'Motif_database/YEASTRACT_20130918.meme'), shell=True)\n",
    "    subprocess.call('cp %s/tomtom/tomtom.tsv %s/tomtom/tomtom.txt' %(out_dir, out_dir), shell=True)\n",
    "    filter_names = name_filters(num_filters, '%s/tomtom/tomtom.txt'%out_dir, 'Motif_database/YEASTRACT_20130918.meme')\n",
    "    \n",
    "    table_out = open('%s/table.txt'%out_dir, 'w')\n",
    "\n",
    "    # print header for later panda reading\n",
    "    table = PrettyTable([\"Filter\", \"consensus\",\"annotation\",\"ic\",\"mean\",\"std\"])\n",
    "    header_cols = ('', 'consensus', 'annotation', 'ic', 'mean', 'std')\n",
    "    print('%3s  %19s  %10s  %5s  %6s  %6s' % header_cols, file=table_out)\n",
    "    \n",
    "    for f in range(num_filters):\n",
    "        # collapse to a consensus motif\n",
    "        consensus = filter_motif(filter_weights[f,:,:])\n",
    "\n",
    "        # grab annotation\n",
    "        annotation = '.'\n",
    "        name_pieces = filter_names[f].split('_')\n",
    "        if len(name_pieces) > 1:\n",
    "            annotation = name_pieces[1]\n",
    "        # plot density of filter output scores\n",
    "        fmean, fstd = plot_score_density(np.ravel(filter_outs[: , f , :]), '%s/filter%d_dens.pdf' % (out_dir,f))\n",
    "\n",
    "        row_cols = (f, consensus, annotation, filters_ic[f], fmean, fstd)\n",
    "        table.add_row(list(row_cols))\n",
    "        print( '%-3d  %19s  %10s  %5.2f  %6.4f  %6.4f' % row_cols, file=table_out)\n",
    "        \n",
    "    table_out.close()\n",
    "    print(table.get_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d01a32e",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "618cb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "global device\n",
    "global model_dir\n",
    "global results_dir\n",
    "global data_dir\n",
    "global verbose\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_dir = 'model'\n",
    "results_dir = 'results'\n",
    "data_dir = 'Data'\n",
    "verbose = False\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "if not os.path.exists(results_dir+'/tomtom'):\n",
    "    os.mkdir(results_dir+'/tomtom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c73b4a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1620, 186, 1806, 178)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = data_dir+'/S288C_reference_sequence_R64-3-1_20210421.fsa'\n",
    "peak_file = data_dir+'/Condensin_peaks_Log.bed'#data_dir+'/Condensin_peaks_quiescence.bed'\n",
    "seq_length = 500\n",
    "motif_length = 24\n",
    "cross_chrom = True\n",
    "include_dinuc = True\n",
    "calib_data,valid_data,train_data,test_data,peak_sequences_train,peak_sequences_test = extract_data(data_file,peak_file,motif_length,\n",
    "                                                                                                   seq_length,cross_chrom,include_dinuc)\n",
    "len(calib_data),len(valid_data),len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50fc972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_dataset=dataset(calib_data)\n",
    "valid_dataset=dataset(valid_data)\n",
    "train_dataset=dataset(train_data)\n",
    "test_dataset=dataset(test_data)\n",
    "batch_size = 64\n",
    "calib_loader = DataLoader(dataset=calib_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "734a0538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 out of 30\n",
      "early stopping at epoch  1\n",
      "model 2 out of 30\n",
      "early stopping at epoch  12\n",
      "model 3 out of 30\n",
      "early stopping at epoch  6\n",
      "model 4 out of 30\n",
      "early stopping at epoch  244\n",
      "model 5 out of 30\n",
      "early stopping at epoch  33\n",
      "model 6 out of 30\n",
      "early stopping at epoch  27\n",
      "model 7 out of 30\n",
      "early stopping at epoch  346\n",
      "model 8 out of 30\n",
      "early stopping at epoch  1\n",
      "model 9 out of 30\n",
      "early stopping at epoch  282\n",
      "model 10 out of 30\n",
      "no early stopping\n",
      "model 11 out of 30\n",
      "early stopping at epoch  12\n",
      "model 12 out of 30\n",
      "early stopping at epoch  1\n",
      "model 13 out of 30\n",
      "early stopping at epoch  290\n",
      "model 14 out of 30\n",
      "no early stopping\n",
      "model 15 out of 30\n",
      "no early stopping\n",
      "model 16 out of 30\n",
      "early stopping at epoch  218\n",
      "model 17 out of 30\n",
      "early stopping at epoch  6\n",
      "model 18 out of 30\n",
      "early stopping at epoch  43\n",
      "model 19 out of 30\n",
      "no early stopping\n",
      "model 20 out of 30\n",
      "early stopping at epoch  43\n",
      "model 21 out of 30\n",
      "early stopping at epoch  48\n",
      "model 22 out of 30\n",
      "early stopping at epoch  427\n",
      "model 23 out of 30\n",
      "early stopping at epoch  20\n",
      "model 24 out of 30\n",
      "early stopping at epoch  23\n",
      "model 25 out of 30\n",
      "no early stopping\n",
      "model 26 out of 30\n",
      "early stopping at epoch  218\n",
      "model 27 out of 30\n",
      "early stopping at epoch  8\n",
      "model 28 out of 30\n",
      "early stopping at epoch  9\n",
      "model 29 out of 30\n",
      "early stopping at epoch  19\n",
      "model 30 out of 30\n",
      "early stopping at epoch  16\n"
     ]
    }
   ],
   "source": [
    "num_motif_list = [30,40,60]\n",
    "num_conv_layers_list = [1,2]\n",
    "dropprob_list = [0, 0.15, 0.3]\n",
    "learning_rate_list = [10**-5,10**-4,10**-3,10**-2]\n",
    "max_num_models = 30\n",
    "maxepochs = 500\n",
    "epochs_for_early_stop = 50\n",
    "best_hyperparameters,results = Calibrate_model(calib_loader,valid_loader, num_motif_list, num_conv_layers_list , dropprob_list,\n",
    "                                               learning_rate_list, max_num_models=max_num_models, maxepochs=maxepochs,\n",
    "                                               epochs_for_early_stop=epochs_for_early_stop,motif_len=motif_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab6eecc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_conv_layers</th>\n",
       "      <th>num_motif</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>282</td>\n",
       "      <td>0.976293</td>\n",
       "      <td>0.977569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>218</td>\n",
       "      <td>0.963482</td>\n",
       "      <td>0.969429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>33</td>\n",
       "      <td>0.960010</td>\n",
       "      <td>0.968901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>290</td>\n",
       "      <td>0.959531</td>\n",
       "      <td>0.965703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>244</td>\n",
       "      <td>0.954502</td>\n",
       "      <td>0.961075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  num_conv_layers num_motif  Dropout  Learning Rate epochs     AUROC     AUPRC\n",
       "0               2        60     0.15         0.0001    282  0.976293  0.977569\n",
       "0               2        40     0.15         0.0001    218  0.963482  0.969429\n",
       "0               2        60     0.15         0.0010     33  0.960010  0.968901\n",
       "0               1        60     0.00         0.0001    290  0.959531  0.965703\n",
       "0               2        30     0.15         0.0001    244  0.954502  0.961075"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "322d7eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_epochs': 282,\n",
       " 'best_num_motif': 60,\n",
       " 'best_num_conv_layers': 2,\n",
       " 'best_dropprob': 0.15,\n",
       " 'best_l_rate': 0.0001}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "314fee2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no early stopping\n",
      "+------------------------+------------+\n",
      "|        Modules         | Parameters |\n",
      "+------------------------+------------+\n",
      "|  conv_layer.0.weight   |    5760    |\n",
      "|   conv_layer.0.bias    |     60     |\n",
      "|  conv_layer.3.weight   |   64800    |\n",
      "|   conv_layer.3.bias    |     90     |\n",
      "| project.to_attn_logits |    8100    |\n",
      "|  classifier.0.weight   |    8100    |\n",
      "|   classifier.0.bias    |     90     |\n",
      "|  classifier.3.weight   |     90     |\n",
      "|   classifier.3.bias    |     1      |\n",
      "+------------------------+------------+\n",
      "\n",
      " Total Trainable Params: 87091\n"
     ]
    }
   ],
   "source": [
    "maxepochs = best_hyperparameters['best_epochs']\n",
    "num_motif = best_hyperparameters['best_num_motif']\n",
    "num_conv_layers = best_hyperparameters['best_num_conv_layers']\n",
    "dropprob = best_hyperparameters['best_dropprob']\n",
    "l_rate = best_hyperparameters['best_l_rate']\n",
    "epochs_for_early_stop = 0\n",
    "model = Network(num_motif , motif_length , num_conv_layers , dropprob).to(device)\n",
    "best_model,epochs,train_losses,valid_losses = Train_model(model,train_loader,valid_loader,l_rate ,maxepochs,\n",
    "                                                          epochs_for_early_stop,save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fda8ee23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9257669486175987, 0.9414793761090573)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc,prc = Test_model(best_model,test_loader)\n",
    "auc,prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "227ac032",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = best_model.conv[0].weight.detach().cpu().numpy()\n",
    "bias = best_model.conv[0].bias.detach().cpu().numpy()\n",
    "motif_sequences=generate_onehot_data(peak_sequences_test,motif_length,1,include_dinuc=False)\n",
    "motif_dataset=dataset(motif_sequences)\n",
    "motif_loader = DataLoader(dataset=motif_dataset,\n",
    "                          batch_size=batch_size,shuffle=False)\n",
    "out_model = conv_output(weights,bias,device)\n",
    "filter_output = return_filter_outputs(out_model,motif_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b81cbeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 4, 24)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3342abf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 60, 523)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f0385d",
   "metadata": {},
   "source": [
    "# Motif extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "17059f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The output directory 'results/tomtom' already exists.\n",
      "Its contents will be overwritten.\n",
      "Processing query 1 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.989922\n",
      "#   Estimated pi_0=0.989922\n",
      "Processing query 2 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.991982\n",
      "#   Estimated pi_0=0.991982\n",
      "Processing query 3 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.998847\n",
      "#   Estimated pi_0=0.998847\n",
      "Processing query 4 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.989402\n",
      "#   Estimated pi_0=0.989402\n",
      "Processing query 5 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.985708\n",
      "#   Estimated pi_0=0.987332\n",
      "Processing query 6 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.98277\n",
      "#   Estimated pi_0=0.983883\n",
      "Processing query 7 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.98277\n",
      "#   Estimated pi_0=0.983329\n",
      "Processing query 8 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.996505\n",
      "#   Estimated pi_0=0.996787\n",
      "Processing query 9 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.993355\n",
      "#   Estimated pi_0=0.993355\n",
      "Processing query 10 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.991472\n",
      "#   Estimated pi_0=0.991982\n",
      "Processing query 11 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.995414\n",
      "#   Estimated pi_0=0.995414\n",
      "Processing query 12 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00365\n",
      "#   Estimated pi_0=1\n",
      "Processing query 13 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.990782\n",
      "#   Estimated pi_0=0.991295\n",
      "Processing query 14 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.996013\n",
      "#   Estimated pi_0=0.998847\n",
      "Processing query 15 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00091\n",
      "#   Estimated pi_0=1\n",
      "Processing query 16 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.989922\n",
      "#   Estimated pi_0=0.989922\n",
      "Processing query 17 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00434\n",
      "#   Estimated pi_0=1\n",
      "Processing query 18 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.985262\n",
      "#   Estimated pi_0=0.987863\n",
      "Processing query 19 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.988845\n",
      "#   Estimated pi_0=0.989236\n",
      "Processing query 20 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.992235\n",
      "#   Estimated pi_0=0.99816\n",
      "Processing query 21 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.98749\n",
      "#   Estimated pi_0=0.989922\n",
      "Processing query 22 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.973098\n",
      "#   Estimated pi_0=0.973098\n",
      "Processing query 23 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.976207\n",
      "#   Estimated pi_0=0.978227\n",
      "Processing query 24 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.983607\n",
      "#   Estimated pi_0=0.984861\n",
      "Processing query 25 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.988183\n",
      "#   Estimated pi_0=0.990609\n",
      "Processing query 26 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.993038\n",
      "#   Estimated pi_0=0.995414\n",
      "Processing query 27 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.982906\n",
      "#   Estimated pi_0=0.98541\n",
      "Processing query 28 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.990609\n",
      "#   Estimated pi_0=0.990609\n",
      "Processing query 29 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.992668\n",
      "#   Estimated pi_0=0.992668\n",
      "Processing query 30 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.989922\n",
      "#   Estimated pi_0=0.989922\n",
      "Processing query 31 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.999533\n",
      "#   Estimated pi_0=0.999533\n",
      "Processing query 32 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.982503\n",
      "#   Estimated pi_0=0.982503\n",
      "Processing query 33 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.985952\n",
      "#   Estimated pi_0=0.987863\n",
      "Processing query 34 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.967849\n",
      "#   Estimated pi_0=0.967849\n",
      "Processing query 35 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.982503\n",
      "#   Estimated pi_0=0.982503\n",
      "Processing query 36 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.988877\n",
      "#   Estimated pi_0=0.989922\n",
      "Processing query 37 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.988183\n",
      "#   Estimated pi_0=0.988183\n",
      "Processing query 38 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.990957\n",
      "#   Estimated pi_0=0.993542\n",
      "Processing query 39 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.993038\n",
      "#   Estimated pi_0=0.994041\n",
      "Processing query 40 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.986642\n",
      "#   Estimated pi_0=0.987863\n",
      "Processing query 41 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.991472\n",
      "#   Estimated pi_0=0.992668\n",
      "Processing query 42 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.983883\n",
      "#   Estimated pi_0=0.983883\n",
      "Processing query 43 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.98277\n",
      "#   Estimated pi_0=0.985803\n",
      "Processing query 44 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.991472\n",
      "#   Estimated pi_0=0.994041\n",
      "Processing query 45 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.989236\n",
      "#   Estimated pi_0=0.989236\n",
      "Processing query 46 out of 60 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.995612\n",
      "#   Estimated pi_0=0.995612\n",
      "Processing query 47 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.984307\n",
      "#   Estimated pi_0=0.984716\n",
      "Processing query 48 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.990782\n",
      "#   Estimated pi_0=0.991295\n",
      "Processing query 49 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.983329\n",
      "#   Estimated pi_0=0.983744\n",
      "Processing query 50 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.989922\n",
      "#   Estimated pi_0=0.989922\n",
      "Processing query 51 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.991472\n",
      "#   Estimated pi_0=0.992668\n",
      "Processing query 52 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.995414\n",
      "#   Estimated pi_0=0.995414\n",
      "Processing query 53 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.985708\n",
      "#   Estimated pi_0=0.987863\n",
      "Processing query 54 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.987176\n",
      "#   Estimated pi_0=0.987176\n",
      "Processing query 55 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.991472\n",
      "#   Estimated pi_0=0.991982\n",
      "Processing query 56 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.998847\n",
      "#   Estimated pi_0=0.998847\n",
      "Processing query 57 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 1.00297\n",
      "#   Estimated pi_0=1\n",
      "Processing query 58 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.985558\n",
      "#   Estimated pi_0=0.987332\n",
      "Processing query 59 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.994041\n",
      "#   Estimated pi_0=0.994041\n",
      "Processing query 60 out of 60 \n",
      "# Computing q-values.\n",
      "#   Estimating pi_0 from all 1464 observed p-values.\n",
      "#   Estimating pi_0.\n",
      "# Minimal pi_zero = 0.98749\n",
      "#   Estimated pi_0=0.989922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/tomtom/tomtom.txt Motif_database/YEASTRACT_20130918.meme\n",
      "+--------+--------------------------+------------+---------------------+-------------+-------------+\n",
      "| Filter |        consensus         | annotation |          ic         |     mean    |     std     |\n",
      "+--------+--------------------------+------------+---------------------+-------------+-------------+\n",
      "|   0    | TTCCCCCTTTAGTATAACGTCTTT |   Hsf1p    |  3.862537484004835  |  0.16756703 |  0.2165502  |\n",
      "|   1    | TGGACGCCGCATAAAGCATGAATA |   Sum1p    |  5.475368470963823  |  0.19795603 |  0.22485325 |\n",
      "|   2    | GGCGGAGCGGAGTGGGATCTGCCA |   Hsf1p    |  1.2088416860946736 |  0.19239339 |  0.2392636  |\n",
      "|   3    | ACGTATGTAGAGGGCCAGAGCCTA |   Sum1p    |  1.7061009138313155 | 0.095230035 |  0.1502469  |\n",
      "|   4    | TTCGCGCGTCGTGAAAAAATATTG |   Sum1p    |  3.6595537483848246 |  0.15370853 |  0.18357283 |\n",
      "|   5    | ATTGATTGATGATGGTTGTAAATA |   Sum1p    |  11.037378486963346 |  0.40942827 |  0.34638217 |\n",
      "|   6    | CGAAGATTTGCTACTTTTGACTGG |   Sum1p    |  2.5032861848549928 |  0.22546935 |  0.21616627 |\n",
      "|   7    | AAAGGGGGAGACCAGGACACTACC |   Sum1p    |  1.0545061570064125 |  0.07837706 |  0.1493368  |\n",
      "|   8    | TCCGCGTGTGTGCTAAGCGTGCTC |   Hsf1p    |  1.023971926373611  |  0.11585127 |  0.15714565 |\n",
      "|   9    | GCCTTTGTTTTTAAGTTATGCGCG |   Sum1p    |  3.148519549061307  |  0.13936871 |  0.18046728 |\n",
      "|   10   | TTCGGACTGATGATTAGCGCTGAA |   Hsf1p    |  1.2221954509644284 |  0.07291577 |  0.1252757  |\n",
      "|   11   | ATTTAGTCTTTGCTTGAGCCGCCA |     .      | 0.40916332894579077 | 0.115589194 |  0.17748973 |\n",
      "|   12   | GTAGTTATCTCTCGACGCGTGAGA |   Sum1p    | -0.1324161653885766 |  0.06265298 |  0.11807689 |\n",
      "|   13   | TGAGGTCCAGGGGTCGGCACTTCC |   Hsf1p    |  1.493628491057771  |  0.27530298 |  0.31644315 |\n",
      "|   14   | GCCGTGCCATGACAACCGGGCCGA |     .      |  1.8423696250022117 |  0.3010019  |  0.27680206 |\n",
      "|   15   | ATGTACGTCTGCACGCGTAGGAAA |   Hsf1p    |  2.9301181318900387 |  0.12591934 |  0.17061515 |\n",
      "|   16   | TAATCGTTAGCCGGCTGCATTCGG |     .      |  0.7845590524281096 | 0.048510704 |  0.10269147 |\n",
      "|   17   | GGGACGGTAGCCGGAGGTTATTTC |   Sum1p    |  4.926400160599744  | 0.056921933 |  0.11216429 |\n",
      "|   18   | TAGGGCGTAATATGGCCTACCAAT |   Sum1p    |  6.228718081597387  |  0.18240556 |  0.19897944 |\n",
      "|   19   | CTGCATCGGGGGCGGCAGGGGCGG |     .      |  4.452007969619623  |  0.06331897 |  0.1602857  |\n",
      "|   20   | AACTACTATGATAGGCAAAACGAA |   Sum1p    |  7.528495331374046  |  0.29387626 |  0.25233546 |\n",
      "|   21   | GTGTACTTCACGTGACCAGGGCAC |     .      |  1.4270831742386145 |  0.11181479 |  0.18189083 |\n",
      "|   22   | GCGCCTGGCGTAGCTTATCGGCGG |     .      |  2.9063074791081536 | 0.060416956 | 0.123034924 |\n",
      "|   23   | TTTTGAGTTTATCACGGTTACTCA |   Sum1p    |  1.853698750230857  |  0.23848619 |  0.25156304 |\n",
      "|   24   | TTTTCCTCTTCGTGTTGTCTTATA |   Sum1p    |  8.516643991995135  |  0.4097434  |  0.34590018 |\n",
      "|   25   | CTTTGCCACTTTTGCTACCGTGGT |   Nhp6bp   |  0.8497239539135168 |  0.09465722 |  0.14903039 |\n",
      "|   26   | ATGTTTAGGATGAAGCTGAAACTG |   Sum1p    |  3.5829260304526045 |  0.15541178 |  0.18430236 |\n",
      "|   27   | CTCCGTTTATATCTGTTATTCTAT |   Sum1p    |  6.238285846061667  |  0.3198754  |  0.27116838 |\n",
      "|   28   | ATCATATATTCTTCTTCCTCCTTC |   Sum1p    |  3.4196707521564287 |  0.32161066 |  0.27833724 |\n",
      "|   29   | CCTCTCTCGTTGCCCTTTGCTTGG |   Hsf1p    |  0.6941172536371791 |  0.16487736 |  0.20050533 |\n",
      "|   30   | ACACTGCTGCTGTTAATGCCACTG |     .      |  3.448348188051786  |  0.17193423 |  0.2025841  |\n",
      "|   31   | ATCGGTTAGTCATATTTACTGGTA |   Sum1p    |  6.843843601221335  |  0.20983241 |  0.24485442 |\n",
      "|   32   | TGTTTATACTACTTCAAGCAATAC |   Sum1p    |  3.644528141152023  |  0.13290584 |  0.17585306 |\n",
      "|   33   | AAAAAGAAGCATAAAACGCCGTCG |   Sum1p    |  0.8242110534233877 |  0.28363198 |  0.28973448 |\n",
      "|   34   | AGCACACATTCATAGTGAATGATT |   Sum1p    |  9.640389116510024  |  0.27490923 |  0.2618953  |\n",
      "|   35   | TGTTTCTTGAGAGATGGCTCATAC |   Sum1p    |   5.24647636244466  |  0.31425983 |  0.2649813  |\n",
      "|   36   | TACGTGGGGTCTTTATGAGCATTT |   Sum1p    |   5.33380545743971  |  0.32986623 |  0.26683354 |\n",
      "|   37   | TACGACACCGAAACCTGCTTCTAA |   Sum1p    |  2.8715050266318247 |  0.10249324 |  0.15263551 |\n",
      "|   38   | CGAGGTCTTGAACTCCTTCAACGA |   Sum1p    |  1.1403409998920746 |  0.05071011 |  0.11196901 |\n",
      "|   39   | CTGTAGAAAAAGCATATCTGGACG |   Sum1p    |  2.971771085138457  |  0.31092444 |  0.2709425  |\n",
      "|   40   | GACAATTGTGGAGAAGAAGTGGAG |   Hsf1p    |  1.9834836215995888 |  0.07291901 |  0.1335229  |\n",
      "|   41   | CTCTTTCTAATTTACTTTTAGTTT |   Sum1p    |  7.182453494440779  |  0.46119863 |  0.34275988 |\n",
      "|   42   | AGTGGATACACAATCTGACTGGGC |   Sum1p    |  4.926896213099384  |  0.14673139 |  0.19894607 |\n",
      "|   43   | CTCTTTCGCACCAGCAAGAGCTGG |   Hsf1p    |  0.3368794869822851 |  0.18220387 |  0.20217155 |\n",
      "|   44   | AGACACTGTCCAGACAACTCACGT |   Sum1p    |  3.6466546567504885 |  0.09365339 |  0.13886017 |\n",
      "|   45   | AGTACTATTTCGGAACCTTTCTTC |   Hsf1p    |  2.094827824698615  |  0.10773415 |  0.1591259  |\n",
      "|   46   | CCTTAGTGTGACAGCTTAAGGGTG |   Sum1p    |  0.7105799278471512 | 0.055330537 | 0.116814315 |\n",
      "|   47   | CCGTTGCTTGTGTTCCACTGTTGT |   Sum1p    |  4.5336681751706625 |  0.13437234 |  0.17759962 |\n",
      "|   48   | AACGTAAATTAGCATACATGCTGA |   Sum1p    |  5.749437547160838  |  0.13770518 |  0.17116842 |\n",
      "|   49   | TCGAAGTTCTGAGTCTCATTGAAT |   Sum1p    |  6.415767707993674  |  0.13934657 |  0.17609079 |\n",
      "|   50   | GTCGGAGGGTAGTGTGGCTTCACA |   Sum1p    |  5.658313036978435  | 0.082268745 |  0.12841837 |\n",
      "|   51   | GCTGGTCCCGTCAACAAAAGAAGC |     .      |  2.152047536802589  | 0.069106005 |  0.13457817 |\n",
      "|   52   | CAAGCTCGAAATTCTAAATCCAGA |   Sum1p    |  3.227565805227834  |  0.39999792 |  0.3013899  |\n",
      "|   53   | CCATGAATTTGTACGCAAAGATGC |   Sum1p    |   2.35119758554482  |  0.20538697 |  0.22645919 |\n",
      "|   54   | CTAAAGAGTGAACGAGGGTTTAAG |   Sum1p    |  1.1324791369320202 | 0.048189096 | 0.101922505 |\n",
      "|   55   | TAGACCATGCCGAAACAAAAGGTG |     .      |  0.5559229172794429 |  0.08279478 |  0.13717292 |\n",
      "|   56   | GCAGTGGCGGCAGTGGTGTTAGGG |     .      |  4.453903376093243  | 0.047444217 |  0.11447023 |\n",
      "|   57   | GTAGGCCTCTCGTCGGTATGTATA |   Sum1p    |  6.272593416467997  |  0.29515702 |  0.22608656 |\n",
      "|   58   | TGAGCAGGCTAGTTATGGCTCGCC |   Hsf1p    |  0.3782461546682987 |  0.19424137 |  0.1958695  |\n",
      "|   59   | ACGATTACGCACATTTAGTAACAT |   Sum1p    |  6.540623574608252  |  0.47662774 |   0.32074   |\n",
      "+--------+--------------------------+------------+---------------------+-------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "get_motif(weights,filter_output,peak_sequences_test,results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac0d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
